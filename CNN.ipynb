{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWoHF3eJXeWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ad737e6c-9abc-4be8-e229-6eb8a216f66f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMXmQWEdr54Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "37b61b21-29ed-4383-a3af-2eb378822bac"
      },
      "source": [
        "!pip install biopython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.6/dist-packages (1.77)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjrlYH4iXDxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Bio.SeqIO import parse\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from Bio.Seq import Seq\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import keras\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, LeakyReLU\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from collections import Counter\n",
        "from sklearn.utils import class_weight\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjQJiovXXDxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/USA_removed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz7A9VZCXDxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_to_array(my_string):\n",
        "    my_string = my_string.lower()\n",
        "    my_string = re.sub('[^acgt]', 'z', my_string)\n",
        "    my_array = np.array(list(my_string))\n",
        "    return my_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otoHagIgXDxe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b32ef695-de1e-413b-9f47-841b17ea0919"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(np.array(['a','c','g','t','z']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH8w1VSRXDxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ordinal_encoder(my_array):\n",
        "    \n",
        "    integer_encoded = label_encoder.transform(my_array)\n",
        "    float_encoded = integer_encoded.astype(float)\n",
        "    float_encoded[float_encoded == 0] = 0.25 # A\n",
        "    float_encoded[float_encoded == 1] = 0.50 # C\n",
        "    float_encoded[float_encoded == 2] = 0.75 # G\n",
        "    float_encoded[float_encoded == 3] = 1.00 # T\n",
        "    float_encoded[float_encoded == 4] = 0.00 # anything else, z\n",
        "    \n",
        "    return float_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhb-cZleXDxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4ba59499-854d-44a5-ebbe-260bcee6d45f"
      },
      "source": [
        "data=df[[\"Sequence\",\"Geo_Location\"]]\n",
        "data=data[data[\"Sequence\"].notna()]\n",
        "\n",
        "dummy=[]\n",
        "dum=np.array(dummy)\n",
        "\n",
        "form={\"inp_seq\":dum}\n",
        "\n",
        "seq_df = pd.DataFrame (form, columns = ['inp_seq'])\n",
        "\n",
        "seq_list=[]\n",
        "\n",
        "for idx, seq in enumerate(list(data[\"Sequence\"])):\n",
        "    arr=ordinal_encoder(string_to_array(seq))\n",
        "    seq_list.append(arr)\n",
        "    \n",
        "seq_df[\"inp_seq\"]=seq_list\n",
        "\n",
        "final_data= data.assign(enc_seq=seq_df)\n",
        "\n",
        "final_data=final_data[[\"enc_seq\",\"Geo_Location\"]]\n",
        "\n",
        "final_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>enc_seq</th>\n",
              "      <th>Geo_Location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.5, 0.5, 0.25, 0.25, 0.5, 1.0, 1.0, 1.0, 0.5...</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1.0, 0.5, 0.5, 0.5, 0.25, 0.75, 0.75, 1.0, 0....</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.25, 0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 0.25, 0...</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 0.75, 0.25, 1....</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.25, 0.25, 0.25, 0.75, 0.75, 1.0, 1.0, 1.0, ...</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4479</th>\n",
              "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4480</th>\n",
              "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
              "      <td>Washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4481</th>\n",
              "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
              "      <td>Washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4482</th>\n",
              "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4483</th>\n",
              "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4484 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                enc_seq Geo_Location\n",
              "0     [0.5, 0.5, 0.25, 0.25, 0.5, 1.0, 1.0, 1.0, 0.5...     Virginia\n",
              "1     [1.0, 0.5, 0.5, 0.5, 0.25, 0.75, 0.75, 1.0, 0....     Virginia\n",
              "2     [0.25, 0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 0.25, 0...     Virginia\n",
              "3     [0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 0.75, 0.25, 1....     Virginia\n",
              "4     [0.25, 0.25, 0.25, 0.75, 0.75, 1.0, 1.0, 1.0, ...     Virginia\n",
              "...                                                 ...          ...\n",
              "4479  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...   California\n",
              "4480  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...   Washington\n",
              "4481  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...   Washington\n",
              "4482  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...   California\n",
              "4483  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...   California\n",
              "\n",
              "[4484 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8tt8sE-XDxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_maxLen(enc_seq):\n",
        "    \n",
        "    max=0\n",
        "    for row in enc_seq:\n",
        "        #print(type(row))\n",
        "        if(len(row)>max):\n",
        "            max=len(row)\n",
        "    \n",
        "    \n",
        "    return max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrjHM7nUXDx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def append_arr(enc_seq, max_len):\n",
        "    \n",
        "    seq_l=list(enc_seq)\n",
        "    for i in range(len(seq_l),max_len):\n",
        "        seq_l.append(0)\n",
        "        \n",
        "    new_seq_ar=np.array(seq_l)\n",
        "\n",
        "        \n",
        "    return new_seq_ar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br8ums-2XDx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "00966c45-3301-49f7-ba90-e2067a26346f"
      },
      "source": [
        "import math\n",
        "\n",
        "max_len=get_maxLen(final_data[\"enc_seq\"])\n",
        "print(\"max_len is\",max_len)\n",
        "if max_len%2 !=0:\n",
        "    max_len += 1\n",
        "\n",
        "n = 1\n",
        "for i in range(1, math.floor(math.sqrt(max_len))):\n",
        "    if max_len%i==0:\n",
        "        n = i\n",
        "\n",
        "padded_seq_list=[]\n",
        "\n",
        "for index, row in final_data.iterrows():\n",
        "    seq_ar=append_arr(row[\"enc_seq\"],max_len)\n",
        "    padded_seq_list.append(seq_ar)\n",
        "\n",
        "dummy=[]\n",
        "dum=np.array(dummy)\n",
        "form={\"padded_enc_seq\":dum}\n",
        "padded_seq_df = pd.DataFrame (form, columns = ['padded_enc_seq'])\n",
        "\n",
        "padded_seq_df[\"padded_enc_seq\"]=padded_seq_list\n",
        "\n",
        "padded_final_data= final_data.assign(padded_enc_seq=padded_seq_df)\n",
        "\n",
        "padded_final_data=padded_final_data[[\"padded_enc_seq\",\"Geo_Location\"]]\n",
        "\n",
        "padded_final_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_len is 29921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>padded_enc_seq</th>\n",
              "      <th>Geo_Location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.5, 0.5, 0.25, 0.25, 0.5, 1.0, 1.0, 1.0, 0.5...</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1.0, 0.5, 0.5, 0.5, 0.25, 0.75, 0.75, 1.0, 0....</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.25, 0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 0.25, 0...</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 0.75, 0.25, 1....</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.25, 0.25, 0.25, 0.75, 0.75, 1.0, 1.0, 1.0, ...</td>\n",
              "      <td>Virginia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      padded_enc_seq Geo_Location\n",
              "0  [0.5, 0.5, 0.25, 0.25, 0.5, 1.0, 1.0, 1.0, 0.5...     Virginia\n",
              "1  [1.0, 0.5, 0.5, 0.5, 0.25, 0.75, 0.75, 1.0, 0....     Virginia\n",
              "2  [0.25, 0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 0.25, 0...     Virginia\n",
              "3  [0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 0.75, 0.25, 1....     Virginia\n",
              "4  [0.25, 0.25, 0.25, 0.75, 0.75, 1.0, 1.0, 1.0, ...     Virginia"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTnqbUsqXDyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_seq(seq, m ,n):\n",
        "    \n",
        "    r_seq=np.reshape(seq,(m,n))\n",
        "    \n",
        "    return r_seq\n",
        "\n",
        "re_seqList=[]\n",
        "\n",
        "for index, row in padded_final_data.iterrows():\n",
        "    seq_ar=reshape_seq(row[\"padded_enc_seq\"],n,max_len//n)\n",
        "    re_seqList.append(seq_ar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfTmmQqXXDyG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "506e7a88-cdc7-4d1c-c846-745e03edc46e"
      },
      "source": [
        "X = np.asarray(re_seqList)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4484, 6, 4987, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVdMOloCXDyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bc9089b-55b9-4196-ee01-3ee233c0ca09"
      },
      "source": [
        "Y = padded_final_data['Geo_Location'].values\n",
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4484,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPGwIk5SXDyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_classes = list(Y)\n",
        "loc_classes = np.array(loc_classes) \n",
        "loc_classes = list(np.unique(loc_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGR_1qKlXDyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38476894-1f5a-4b58-d2b2-cad3585ad874"
      },
      "source": [
        "df = padded_final_data['Geo_Location'].apply(loc_classes.index)\n",
        "Y = df.values\n",
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4484,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5QHcwrgthc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "44bf5c5b-1447-40c2-8519-0b451257ee55"
      },
      "source": [
        "!pip install keras-metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras-metrics) (2.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVA5EwfHXDyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "cvscores=[]\n",
        "num_folds = 3 # there will be 3 folds in it's entirety\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ovoA3TUXDyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d34e97ca-c5a1-435b-b581-cbb6b8733a8b"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4484, 6, 4987, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWGFPxAsXDyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X.shape[1],X.shape[2]\n",
        "Y = keras.utils.to_categorical(Y,8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sQnzE7S8YKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_best = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWly3zgA8l--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CheckMetrics(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.val_accs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        X_val, Y_val = self.validation_data[0],self.validation_data[1]\n",
        "                \n",
        "        Y_val = np.argmax(Y_val,axis=1)\n",
        "        \n",
        "        Y_pred = self.model.predict(X_val)\n",
        "        Y_pred = np.argmax(Y_pred,axis=1)\n",
        "\n",
        "        _val_acc = accuracy_score(Y_val, Y_pred)\n",
        "\n",
        "        self.val_accs.append(_val_acc)\n",
        "        \n",
        "        if _val_acc == max(self.val_accs):\n",
        "            print(\"Validation Accuracy has improved. Saving Model.\")\n",
        "            self.model.save('modelCNNGeo.h5')\n",
        "            model_best = self.model\n",
        "\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K26_wNQ8qBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras_callbacks = CheckMetrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5lkAX-OXDyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab066886-3be1-4960-bd37-90843adb86e6"
      },
      "source": [
        "fold_no = 1\n",
        "num_classes = 8\n",
        "for train,test in kfold.split(X,Y):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, kernel_size=(3,3), activation='relu', input_shape=(img_rows,img_cols,1)))\n",
        "  model.add(Conv2D(16, (3, 3),activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(32, (3,3), padding='same',activation='relu'))\n",
        "  model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  # compilation of model\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "  print('------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  model.fit(X[train],Y[train], batch_size = 64, epochs = 200,verbose = 1, validation_data= (X[test],Y[test]), callbacks=[keras_callbacks])\n",
        "  model_sel = load_model('modelCNNGeo.h5')\n",
        "  Y_pred = model_sel.predict(X[test])\n",
        "  y_pred = np.argmax(Y_pred, axis=1)\n",
        "  print('Confusion matrix - Test')\n",
        "  y_act = np.argmax(Y[test],axis=1)\n",
        "  print(confusion_matrix(y_act,y_pred))\n",
        "  print('Classification report')\n",
        "  target_names= ['California','Connecticut','Florida','Masachusetts','Michigan','New York','Virginia','Washington']\n",
        "  print(classification_report(y_act,y_pred,target_names=target_names))\n",
        "  scores = model_sel.evaluate(X[test],Y[test],verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model_sel.metrics_names[0]} of {scores[0]}; {model_sel.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "  cvscores.append(scores[1]*100)\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Train on 2989 samples, validate on 1495 samples\n",
            "Epoch 1/200\n",
            "2989/2989 [==============================] - 5s 2ms/step - loss: 1.8552 - accuracy: 0.3603 - val_loss: 1.6988 - val_accuracy: 0.4308\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 2/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.6602 - accuracy: 0.4500 - val_loss: 1.5381 - val_accuracy: 0.4970\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 3/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.5792 - accuracy: 0.4751 - val_loss: 1.3933 - val_accuracy: 0.5144\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 4/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.4848 - accuracy: 0.5115 - val_loss: 1.3559 - val_accuracy: 0.5452\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 5/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.4443 - accuracy: 0.5166 - val_loss: 1.3308 - val_accuracy: 0.5565\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 6/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.4297 - accuracy: 0.5018 - val_loss: 1.2778 - val_accuracy: 0.5679\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 7/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.3812 - accuracy: 0.5226 - val_loss: 1.2074 - val_accuracy: 0.5706\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 8/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.3478 - accuracy: 0.5313 - val_loss: 1.2099 - val_accuracy: 0.5779\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 9/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2994 - accuracy: 0.5423 - val_loss: 1.2028 - val_accuracy: 0.5793\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 10/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2915 - accuracy: 0.5493 - val_loss: 1.1738 - val_accuracy: 0.5739\n",
            "Epoch 11/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2604 - accuracy: 0.5524 - val_loss: 1.1730 - val_accuracy: 0.5839\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 12/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2773 - accuracy: 0.5671 - val_loss: 1.1630 - val_accuracy: 0.5846\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 13/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2587 - accuracy: 0.5657 - val_loss: 1.1439 - val_accuracy: 0.6100\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 14/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2482 - accuracy: 0.5661 - val_loss: 1.1512 - val_accuracy: 0.6140\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 15/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1899 - accuracy: 0.5841 - val_loss: 1.1353 - val_accuracy: 0.6094\n",
            "Epoch 16/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1820 - accuracy: 0.5815 - val_loss: 1.1667 - val_accuracy: 0.5913\n",
            "Epoch 17/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1666 - accuracy: 0.5788 - val_loss: 1.1052 - val_accuracy: 0.6227\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 18/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1372 - accuracy: 0.5851 - val_loss: 1.1036 - val_accuracy: 0.6007\n",
            "Epoch 19/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1195 - accuracy: 0.5955 - val_loss: 1.1169 - val_accuracy: 0.6094\n",
            "Epoch 20/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0959 - accuracy: 0.6139 - val_loss: 1.0826 - val_accuracy: 0.6207\n",
            "Epoch 21/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1017 - accuracy: 0.6032 - val_loss: 1.1048 - val_accuracy: 0.6161\n",
            "Epoch 22/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0793 - accuracy: 0.6159 - val_loss: 1.1098 - val_accuracy: 0.6214\n",
            "Epoch 23/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0728 - accuracy: 0.6146 - val_loss: 1.0903 - val_accuracy: 0.6294\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 24/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0613 - accuracy: 0.6236 - val_loss: 1.0714 - val_accuracy: 0.6288\n",
            "Epoch 25/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0541 - accuracy: 0.6112 - val_loss: 1.0675 - val_accuracy: 0.6294\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 26/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0422 - accuracy: 0.6226 - val_loss: 1.0817 - val_accuracy: 0.6408\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 27/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0473 - accuracy: 0.6223 - val_loss: 1.0471 - val_accuracy: 0.6368\n",
            "Epoch 28/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0213 - accuracy: 0.6280 - val_loss: 1.1116 - val_accuracy: 0.6415\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 29/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0254 - accuracy: 0.6219 - val_loss: 1.1350 - val_accuracy: 0.5846\n",
            "Epoch 30/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0103 - accuracy: 0.6219 - val_loss: 1.0920 - val_accuracy: 0.6495\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 31/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0040 - accuracy: 0.6296 - val_loss: 1.0304 - val_accuracy: 0.6468\n",
            "Epoch 32/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0006 - accuracy: 0.6286 - val_loss: 1.0645 - val_accuracy: 0.6375\n",
            "Epoch 33/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9910 - accuracy: 0.6414 - val_loss: 1.0853 - val_accuracy: 0.6328\n",
            "Epoch 34/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9957 - accuracy: 0.6286 - val_loss: 1.0554 - val_accuracy: 0.6288\n",
            "Epoch 35/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9798 - accuracy: 0.6460 - val_loss: 1.0835 - val_accuracy: 0.6308\n",
            "Epoch 36/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9767 - accuracy: 0.6360 - val_loss: 1.1237 - val_accuracy: 0.6388\n",
            "Epoch 37/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9574 - accuracy: 0.6397 - val_loss: 1.0515 - val_accuracy: 0.6415\n",
            "Epoch 38/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9540 - accuracy: 0.6373 - val_loss: 1.1229 - val_accuracy: 0.6495\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 39/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9467 - accuracy: 0.6464 - val_loss: 1.1281 - val_accuracy: 0.6361\n",
            "Epoch 40/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9571 - accuracy: 0.6440 - val_loss: 1.0611 - val_accuracy: 0.6555\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 41/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9401 - accuracy: 0.6484 - val_loss: 1.0716 - val_accuracy: 0.6355\n",
            "Epoch 42/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9333 - accuracy: 0.6531 - val_loss: 1.0593 - val_accuracy: 0.6455\n",
            "Epoch 43/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9372 - accuracy: 0.6567 - val_loss: 1.0206 - val_accuracy: 0.6502\n",
            "Epoch 44/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9200 - accuracy: 0.6618 - val_loss: 1.0853 - val_accuracy: 0.6515\n",
            "Epoch 45/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9145 - accuracy: 0.6587 - val_loss: 1.0267 - val_accuracy: 0.6535\n",
            "Epoch 46/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9113 - accuracy: 0.6688 - val_loss: 1.0469 - val_accuracy: 0.6569\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 47/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9313 - accuracy: 0.6547 - val_loss: 1.0341 - val_accuracy: 0.6682\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 48/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9233 - accuracy: 0.6581 - val_loss: 1.0513 - val_accuracy: 0.6575\n",
            "Epoch 49/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9187 - accuracy: 0.6648 - val_loss: 1.0160 - val_accuracy: 0.6522\n",
            "Epoch 50/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9048 - accuracy: 0.6591 - val_loss: 1.0348 - val_accuracy: 0.6682\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 51/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9016 - accuracy: 0.6608 - val_loss: 1.0547 - val_accuracy: 0.6488\n",
            "Epoch 52/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9019 - accuracy: 0.6661 - val_loss: 1.0774 - val_accuracy: 0.6508\n",
            "Epoch 53/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9036 - accuracy: 0.6614 - val_loss: 1.0344 - val_accuracy: 0.6475\n",
            "Epoch 54/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8745 - accuracy: 0.6688 - val_loss: 1.1028 - val_accuracy: 0.6575\n",
            "Epoch 55/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8946 - accuracy: 0.6624 - val_loss: 1.1314 - val_accuracy: 0.6870\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 56/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8702 - accuracy: 0.6685 - val_loss: 1.0967 - val_accuracy: 0.6856\n",
            "Epoch 57/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8832 - accuracy: 0.6644 - val_loss: 1.1092 - val_accuracy: 0.6575\n",
            "Epoch 58/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8700 - accuracy: 0.6691 - val_loss: 1.1639 - val_accuracy: 0.6702\n",
            "Epoch 59/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8651 - accuracy: 0.6698 - val_loss: 1.1519 - val_accuracy: 0.6763\n",
            "Epoch 60/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8556 - accuracy: 0.6711 - val_loss: 1.1848 - val_accuracy: 0.6742\n",
            "Epoch 61/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8627 - accuracy: 0.6628 - val_loss: 1.1334 - val_accuracy: 0.6635\n",
            "Epoch 62/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8574 - accuracy: 0.6618 - val_loss: 1.0328 - val_accuracy: 0.6809\n",
            "Epoch 63/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8465 - accuracy: 0.6792 - val_loss: 1.1219 - val_accuracy: 0.6796\n",
            "Epoch 64/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8412 - accuracy: 0.6751 - val_loss: 1.1599 - val_accuracy: 0.6816\n",
            "Epoch 65/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8530 - accuracy: 0.6685 - val_loss: 1.2048 - val_accuracy: 0.6609\n",
            "Epoch 66/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8528 - accuracy: 0.6624 - val_loss: 1.0728 - val_accuracy: 0.6749\n",
            "Epoch 67/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8472 - accuracy: 0.6598 - val_loss: 1.1105 - val_accuracy: 0.6756\n",
            "Epoch 68/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8438 - accuracy: 0.6664 - val_loss: 1.2349 - val_accuracy: 0.6796\n",
            "Epoch 69/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8502 - accuracy: 0.6678 - val_loss: 1.0914 - val_accuracy: 0.6716\n",
            "Epoch 70/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8138 - accuracy: 0.6835 - val_loss: 1.1847 - val_accuracy: 0.6803\n",
            "Epoch 71/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8274 - accuracy: 0.6768 - val_loss: 1.0842 - val_accuracy: 0.6803\n",
            "Epoch 72/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8100 - accuracy: 0.6802 - val_loss: 1.0622 - val_accuracy: 0.6896\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 73/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7883 - accuracy: 0.6902 - val_loss: 1.1658 - val_accuracy: 0.6823\n",
            "Epoch 74/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8048 - accuracy: 0.6992 - val_loss: 1.0803 - val_accuracy: 0.6890\n",
            "Epoch 75/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7947 - accuracy: 0.6902 - val_loss: 1.0177 - val_accuracy: 0.6977\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 76/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7762 - accuracy: 0.6912 - val_loss: 1.0902 - val_accuracy: 0.6916\n",
            "Epoch 77/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7634 - accuracy: 0.6976 - val_loss: 1.2223 - val_accuracy: 0.6783\n",
            "Epoch 78/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7788 - accuracy: 0.7053 - val_loss: 1.0834 - val_accuracy: 0.7064\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 79/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8046 - accuracy: 0.6865 - val_loss: 1.1126 - val_accuracy: 0.7017\n",
            "Epoch 80/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7859 - accuracy: 0.6889 - val_loss: 1.0402 - val_accuracy: 0.6890\n",
            "Epoch 81/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8092 - accuracy: 0.6832 - val_loss: 1.1527 - val_accuracy: 0.6930\n",
            "Epoch 82/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7902 - accuracy: 0.6919 - val_loss: 1.0544 - val_accuracy: 0.7097\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 83/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7879 - accuracy: 0.6949 - val_loss: 1.1633 - val_accuracy: 0.7003\n",
            "Epoch 84/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7631 - accuracy: 0.6972 - val_loss: 1.2000 - val_accuracy: 0.7070\n",
            "Epoch 85/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7788 - accuracy: 0.6902 - val_loss: 1.1672 - val_accuracy: 0.6983\n",
            "Epoch 86/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7883 - accuracy: 0.6899 - val_loss: 1.0768 - val_accuracy: 0.7144\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 87/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7672 - accuracy: 0.7016 - val_loss: 1.1192 - val_accuracy: 0.7043\n",
            "Epoch 88/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7691 - accuracy: 0.6932 - val_loss: 1.3526 - val_accuracy: 0.6916\n",
            "Epoch 89/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7676 - accuracy: 0.6912 - val_loss: 1.0996 - val_accuracy: 0.6997\n",
            "Epoch 90/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7745 - accuracy: 0.7053 - val_loss: 1.0137 - val_accuracy: 0.7171\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 91/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7528 - accuracy: 0.7016 - val_loss: 1.0724 - val_accuracy: 0.7057\n",
            "Epoch 92/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7513 - accuracy: 0.7063 - val_loss: 1.0931 - val_accuracy: 0.7157\n",
            "Epoch 93/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7337 - accuracy: 0.7146 - val_loss: 1.0801 - val_accuracy: 0.7171\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 94/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7596 - accuracy: 0.7109 - val_loss: 1.0250 - val_accuracy: 0.7197\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 95/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7468 - accuracy: 0.7056 - val_loss: 1.1492 - val_accuracy: 0.6957\n",
            "Epoch 96/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7356 - accuracy: 0.7140 - val_loss: 1.1425 - val_accuracy: 0.7151\n",
            "Epoch 97/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7406 - accuracy: 0.7066 - val_loss: 1.1808 - val_accuracy: 0.7070\n",
            "Epoch 98/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7351 - accuracy: 0.7126 - val_loss: 1.0430 - val_accuracy: 0.7104\n",
            "Epoch 99/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7354 - accuracy: 0.7180 - val_loss: 1.0744 - val_accuracy: 0.7217\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 100/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7383 - accuracy: 0.7106 - val_loss: 1.0752 - val_accuracy: 0.7237\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 101/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7236 - accuracy: 0.7146 - val_loss: 1.0850 - val_accuracy: 0.7244\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 102/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6997 - accuracy: 0.7257 - val_loss: 1.0874 - val_accuracy: 0.7177\n",
            "Epoch 103/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7144 - accuracy: 0.7203 - val_loss: 1.1320 - val_accuracy: 0.7184\n",
            "Epoch 104/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7471 - accuracy: 0.6982 - val_loss: 1.1513 - val_accuracy: 0.7231\n",
            "Epoch 105/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7063 - accuracy: 0.7193 - val_loss: 1.1079 - val_accuracy: 0.7278\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 106/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7300 - accuracy: 0.7150 - val_loss: 1.2498 - val_accuracy: 0.7197\n",
            "Epoch 107/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7296 - accuracy: 0.7190 - val_loss: 1.1452 - val_accuracy: 0.7197\n",
            "Epoch 108/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6882 - accuracy: 0.7327 - val_loss: 1.1674 - val_accuracy: 0.7284\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 109/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7114 - accuracy: 0.7240 - val_loss: 1.2564 - val_accuracy: 0.7130\n",
            "Epoch 110/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7004 - accuracy: 0.7216 - val_loss: 1.1845 - val_accuracy: 0.7171\n",
            "Epoch 111/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7288 - accuracy: 0.7237 - val_loss: 1.1713 - val_accuracy: 0.7244\n",
            "Epoch 112/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6870 - accuracy: 0.7344 - val_loss: 1.0942 - val_accuracy: 0.7191\n",
            "Epoch 113/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7071 - accuracy: 0.7290 - val_loss: 1.2387 - val_accuracy: 0.7144\n",
            "Epoch 114/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7005 - accuracy: 0.7153 - val_loss: 1.1707 - val_accuracy: 0.7251\n",
            "Epoch 115/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7048 - accuracy: 0.7293 - val_loss: 1.2118 - val_accuracy: 0.7204\n",
            "Epoch 116/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6825 - accuracy: 0.7267 - val_loss: 1.3030 - val_accuracy: 0.7291\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 117/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7140 - accuracy: 0.7160 - val_loss: 1.1493 - val_accuracy: 0.7244\n",
            "Epoch 118/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7014 - accuracy: 0.7200 - val_loss: 1.1602 - val_accuracy: 0.7211\n",
            "Epoch 119/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6916 - accuracy: 0.7183 - val_loss: 1.2229 - val_accuracy: 0.7204\n",
            "Epoch 120/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6748 - accuracy: 0.7263 - val_loss: 1.1743 - val_accuracy: 0.7324\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 121/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6798 - accuracy: 0.7444 - val_loss: 1.2558 - val_accuracy: 0.7291\n",
            "Epoch 122/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7158 - accuracy: 0.7210 - val_loss: 1.1364 - val_accuracy: 0.7271\n",
            "Epoch 123/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6953 - accuracy: 0.7243 - val_loss: 1.1325 - val_accuracy: 0.7311\n",
            "Epoch 124/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7003 - accuracy: 0.7297 - val_loss: 1.1583 - val_accuracy: 0.7452\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 125/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6730 - accuracy: 0.7447 - val_loss: 1.2721 - val_accuracy: 0.7385\n",
            "Epoch 126/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6665 - accuracy: 0.7524 - val_loss: 1.1699 - val_accuracy: 0.7425\n",
            "Epoch 127/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6696 - accuracy: 0.7397 - val_loss: 1.1794 - val_accuracy: 0.7431\n",
            "Epoch 128/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6646 - accuracy: 0.7467 - val_loss: 1.2697 - val_accuracy: 0.7438\n",
            "Epoch 129/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6595 - accuracy: 0.7447 - val_loss: 1.3496 - val_accuracy: 0.7431\n",
            "Epoch 130/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6522 - accuracy: 0.7534 - val_loss: 1.2942 - val_accuracy: 0.7458\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 131/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6616 - accuracy: 0.7558 - val_loss: 1.2873 - val_accuracy: 0.7592\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 132/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6487 - accuracy: 0.7554 - val_loss: 1.2738 - val_accuracy: 0.7538\n",
            "Epoch 133/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6489 - accuracy: 0.7541 - val_loss: 1.2593 - val_accuracy: 0.7505\n",
            "Epoch 134/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6358 - accuracy: 0.7584 - val_loss: 1.2941 - val_accuracy: 0.7579\n",
            "Epoch 135/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6389 - accuracy: 0.7678 - val_loss: 1.2803 - val_accuracy: 0.7579\n",
            "Epoch 136/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6549 - accuracy: 0.7591 - val_loss: 1.4984 - val_accuracy: 0.7592\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 137/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6280 - accuracy: 0.7635 - val_loss: 1.2329 - val_accuracy: 0.7632\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 138/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6432 - accuracy: 0.7581 - val_loss: 1.1301 - val_accuracy: 0.7619\n",
            "Epoch 139/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6278 - accuracy: 0.7685 - val_loss: 1.2379 - val_accuracy: 0.7645\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 140/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6393 - accuracy: 0.7635 - val_loss: 1.1019 - val_accuracy: 0.7619\n",
            "Epoch 141/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6255 - accuracy: 0.7611 - val_loss: 1.2120 - val_accuracy: 0.7625\n",
            "Epoch 142/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6237 - accuracy: 0.7695 - val_loss: 1.1120 - val_accuracy: 0.7639\n",
            "Epoch 143/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6085 - accuracy: 0.7655 - val_loss: 1.2590 - val_accuracy: 0.7706\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 144/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6304 - accuracy: 0.7698 - val_loss: 1.0726 - val_accuracy: 0.7645\n",
            "Epoch 145/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6387 - accuracy: 0.7668 - val_loss: 1.2569 - val_accuracy: 0.7612\n",
            "Epoch 146/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6288 - accuracy: 0.7615 - val_loss: 1.3613 - val_accuracy: 0.7612\n",
            "Epoch 147/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6458 - accuracy: 0.7518 - val_loss: 1.2507 - val_accuracy: 0.7679\n",
            "Epoch 148/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6107 - accuracy: 0.7678 - val_loss: 1.3264 - val_accuracy: 0.7525\n",
            "Epoch 149/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6369 - accuracy: 0.7574 - val_loss: 1.3395 - val_accuracy: 0.7518\n",
            "Epoch 150/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6061 - accuracy: 0.7779 - val_loss: 1.2353 - val_accuracy: 0.7706\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 151/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6120 - accuracy: 0.7678 - val_loss: 1.2870 - val_accuracy: 0.7579\n",
            "Epoch 152/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6055 - accuracy: 0.7772 - val_loss: 1.2632 - val_accuracy: 0.7532\n",
            "Epoch 153/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6302 - accuracy: 0.7598 - val_loss: 1.1292 - val_accuracy: 0.7538\n",
            "Epoch 154/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6058 - accuracy: 0.7725 - val_loss: 1.3099 - val_accuracy: 0.7645\n",
            "Epoch 155/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6317 - accuracy: 0.7621 - val_loss: 1.1989 - val_accuracy: 0.7706\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 156/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5964 - accuracy: 0.7815 - val_loss: 1.2941 - val_accuracy: 0.7732\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 157/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5987 - accuracy: 0.7812 - val_loss: 1.4115 - val_accuracy: 0.7659\n",
            "Epoch 158/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6346 - accuracy: 0.7628 - val_loss: 1.2692 - val_accuracy: 0.7565\n",
            "Epoch 159/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6230 - accuracy: 0.7655 - val_loss: 1.3478 - val_accuracy: 0.7605\n",
            "Epoch 160/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6191 - accuracy: 0.7708 - val_loss: 1.1183 - val_accuracy: 0.7565\n",
            "Epoch 161/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5923 - accuracy: 0.7892 - val_loss: 1.3029 - val_accuracy: 0.7712\n",
            "Epoch 162/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6129 - accuracy: 0.7748 - val_loss: 1.2673 - val_accuracy: 0.7632\n",
            "Epoch 163/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6066 - accuracy: 0.7782 - val_loss: 1.2966 - val_accuracy: 0.7592\n",
            "Epoch 164/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6041 - accuracy: 0.7825 - val_loss: 1.2233 - val_accuracy: 0.7612\n",
            "Epoch 165/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6006 - accuracy: 0.7892 - val_loss: 1.4140 - val_accuracy: 0.7712\n",
            "Epoch 166/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5919 - accuracy: 0.7782 - val_loss: 1.2856 - val_accuracy: 0.7652\n",
            "Epoch 167/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5847 - accuracy: 0.7899 - val_loss: 1.5240 - val_accuracy: 0.7645\n",
            "Epoch 168/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5946 - accuracy: 0.7852 - val_loss: 1.2537 - val_accuracy: 0.7625\n",
            "Epoch 169/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5703 - accuracy: 0.7896 - val_loss: 1.4130 - val_accuracy: 0.7652\n",
            "Epoch 170/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5769 - accuracy: 0.7906 - val_loss: 1.2852 - val_accuracy: 0.7659\n",
            "Epoch 171/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5847 - accuracy: 0.7812 - val_loss: 1.2859 - val_accuracy: 0.7699\n",
            "Epoch 172/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5685 - accuracy: 0.7809 - val_loss: 1.2987 - val_accuracy: 0.7672\n",
            "Epoch 173/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6042 - accuracy: 0.7768 - val_loss: 1.1558 - val_accuracy: 0.7692\n",
            "Epoch 174/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5911 - accuracy: 0.7752 - val_loss: 1.2804 - val_accuracy: 0.7692\n",
            "Epoch 175/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6045 - accuracy: 0.7792 - val_loss: 1.2539 - val_accuracy: 0.7652\n",
            "Epoch 176/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5738 - accuracy: 0.7932 - val_loss: 1.2245 - val_accuracy: 0.7686\n",
            "Epoch 177/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5794 - accuracy: 0.7902 - val_loss: 1.2127 - val_accuracy: 0.7692\n",
            "Epoch 178/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5790 - accuracy: 0.7989 - val_loss: 1.4169 - val_accuracy: 0.7659\n",
            "Epoch 179/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5698 - accuracy: 0.7906 - val_loss: 1.5949 - val_accuracy: 0.7619\n",
            "Epoch 180/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5691 - accuracy: 0.7939 - val_loss: 1.5070 - val_accuracy: 0.7672\n",
            "Epoch 181/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5803 - accuracy: 0.7886 - val_loss: 1.3449 - val_accuracy: 0.7645\n",
            "Epoch 182/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5653 - accuracy: 0.7942 - val_loss: 1.4767 - val_accuracy: 0.7699\n",
            "Epoch 183/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5631 - accuracy: 0.7939 - val_loss: 1.1148 - val_accuracy: 0.7672\n",
            "Epoch 184/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5802 - accuracy: 0.7949 - val_loss: 1.2157 - val_accuracy: 0.7645\n",
            "Epoch 185/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5569 - accuracy: 0.7946 - val_loss: 1.4713 - val_accuracy: 0.7619\n",
            "Epoch 186/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5760 - accuracy: 0.7896 - val_loss: 1.0619 - val_accuracy: 0.7699\n",
            "Epoch 187/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5754 - accuracy: 0.7916 - val_loss: 1.2514 - val_accuracy: 0.7746\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 188/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5677 - accuracy: 0.7899 - val_loss: 1.2721 - val_accuracy: 0.7672\n",
            "Epoch 189/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5686 - accuracy: 0.7889 - val_loss: 1.2027 - val_accuracy: 0.7706\n",
            "Epoch 190/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5581 - accuracy: 0.7986 - val_loss: 1.3051 - val_accuracy: 0.7813\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 191/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5567 - accuracy: 0.7966 - val_loss: 1.6957 - val_accuracy: 0.7572\n",
            "Epoch 192/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5720 - accuracy: 0.7869 - val_loss: 1.3146 - val_accuracy: 0.7746\n",
            "Epoch 193/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5401 - accuracy: 0.8063 - val_loss: 1.3046 - val_accuracy: 0.7799\n",
            "Epoch 194/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5579 - accuracy: 0.7996 - val_loss: 1.6075 - val_accuracy: 0.7739\n",
            "Epoch 195/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5781 - accuracy: 0.7855 - val_loss: 1.2852 - val_accuracy: 0.7759\n",
            "Epoch 196/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5670 - accuracy: 0.7949 - val_loss: 1.6700 - val_accuracy: 0.7592\n",
            "Epoch 197/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5592 - accuracy: 0.7969 - val_loss: 1.3941 - val_accuracy: 0.7739\n",
            "Epoch 198/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5511 - accuracy: 0.7999 - val_loss: 1.3212 - val_accuracy: 0.7779\n",
            "Epoch 199/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5488 - accuracy: 0.7922 - val_loss: 1.2971 - val_accuracy: 0.7726\n",
            "Epoch 200/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5478 - accuracy: 0.7886 - val_loss: 1.3831 - val_accuracy: 0.7706\n",
            "Confusion matrix - Test\n",
            "[[166   3   2   3  30   8  18  24]\n",
            " [  4   6  10   0   6   1   2  12]\n",
            " [  5   2  36   0   3   0   0   3]\n",
            " [ 13   1   4  70   1   1   6  33]\n",
            " [ 12   1   1   4 136   0   1   1]\n",
            " [ 12   0   1   0   0  77   0   1]\n",
            " [ 25   1   1   5   3   1  84  13]\n",
            " [ 24   0   0  12   1   4   8 593]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  California       0.64      0.65      0.64       254\n",
            " Connecticut       0.43      0.15      0.22        41\n",
            "     Florida       0.65      0.73      0.69        49\n",
            "Masachusetts       0.74      0.54      0.63       129\n",
            "    Michigan       0.76      0.87      0.81       156\n",
            "    New York       0.84      0.85      0.84        91\n",
            "    Virginia       0.71      0.63      0.67       133\n",
            "  Washington       0.87      0.92      0.90       642\n",
            "\n",
            "    accuracy                           0.78      1495\n",
            "   macro avg       0.70      0.67      0.67      1495\n",
            "weighted avg       0.77      0.78      0.77      1495\n",
            "\n",
            "Score for fold 1: loss of 1.3050874873347904; accuracy of 78.12709212303162%\n",
            "------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Train on 2989 samples, validate on 1495 samples\n",
            "Epoch 1/200\n",
            "2989/2989 [==============================] - 5s 2ms/step - loss: 1.9011 - accuracy: 0.2874 - val_loss: 1.5303 - val_accuracy: 0.4977\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 2/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.6358 - accuracy: 0.4199 - val_loss: 1.3789 - val_accuracy: 0.5358\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 3/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.5262 - accuracy: 0.4684 - val_loss: 1.2524 - val_accuracy: 0.5425\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 4/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.4758 - accuracy: 0.4978 - val_loss: 1.2427 - val_accuracy: 0.5485\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 5/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.4057 - accuracy: 0.5246 - val_loss: 1.1905 - val_accuracy: 0.6147\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 6/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.3677 - accuracy: 0.5309 - val_loss: 1.2070 - val_accuracy: 0.6087\n",
            "Epoch 7/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.3135 - accuracy: 0.5440 - val_loss: 1.1088 - val_accuracy: 0.6127\n",
            "Epoch 8/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2836 - accuracy: 0.5544 - val_loss: 1.1374 - val_accuracy: 0.6167\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 9/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2873 - accuracy: 0.5631 - val_loss: 1.0828 - val_accuracy: 0.6254\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 10/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2485 - accuracy: 0.5644 - val_loss: 1.0799 - val_accuracy: 0.6227\n",
            "Epoch 11/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2514 - accuracy: 0.5724 - val_loss: 1.0987 - val_accuracy: 0.6361\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 12/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2126 - accuracy: 0.5791 - val_loss: 1.0542 - val_accuracy: 0.6408\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 13/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.2194 - accuracy: 0.5764 - val_loss: 1.2081 - val_accuracy: 0.6428\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 14/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1360 - accuracy: 0.6022 - val_loss: 1.0084 - val_accuracy: 0.6515\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 15/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1488 - accuracy: 0.5972 - val_loss: 1.0161 - val_accuracy: 0.6408\n",
            "Epoch 16/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1354 - accuracy: 0.6059 - val_loss: 1.0182 - val_accuracy: 0.6622\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 17/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1160 - accuracy: 0.6116 - val_loss: 1.0602 - val_accuracy: 0.6455\n",
            "Epoch 18/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.1176 - accuracy: 0.6052 - val_loss: 0.9894 - val_accuracy: 0.6622\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 19/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0711 - accuracy: 0.6176 - val_loss: 0.9746 - val_accuracy: 0.6542\n",
            "Epoch 20/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0573 - accuracy: 0.6260 - val_loss: 1.0024 - val_accuracy: 0.6542\n",
            "Epoch 21/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0652 - accuracy: 0.6290 - val_loss: 0.9716 - val_accuracy: 0.6702\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 22/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0411 - accuracy: 0.6286 - val_loss: 0.9786 - val_accuracy: 0.6515\n",
            "Epoch 23/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0536 - accuracy: 0.6183 - val_loss: 0.9617 - val_accuracy: 0.6702\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 24/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0390 - accuracy: 0.6256 - val_loss: 0.9594 - val_accuracy: 0.6756\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 25/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0151 - accuracy: 0.6407 - val_loss: 0.9715 - val_accuracy: 0.6722\n",
            "Epoch 26/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0141 - accuracy: 0.6390 - val_loss: 0.9529 - val_accuracy: 0.6849\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 27/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9788 - accuracy: 0.6474 - val_loss: 0.9726 - val_accuracy: 0.6749\n",
            "Epoch 28/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 1.0062 - accuracy: 0.6427 - val_loss: 0.9506 - val_accuracy: 0.6629\n",
            "Epoch 29/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9864 - accuracy: 0.6403 - val_loss: 0.9241 - val_accuracy: 0.6849\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 30/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9847 - accuracy: 0.6467 - val_loss: 0.9429 - val_accuracy: 0.6642\n",
            "Epoch 31/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9639 - accuracy: 0.6507 - val_loss: 0.9454 - val_accuracy: 0.6903\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 32/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9718 - accuracy: 0.6514 - val_loss: 0.9500 - val_accuracy: 0.6763\n",
            "Epoch 33/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9452 - accuracy: 0.6611 - val_loss: 0.9289 - val_accuracy: 0.6849\n",
            "Epoch 34/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9657 - accuracy: 0.6567 - val_loss: 0.9136 - val_accuracy: 0.6950\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 35/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9376 - accuracy: 0.6611 - val_loss: 0.9656 - val_accuracy: 0.7050\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 36/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9494 - accuracy: 0.6668 - val_loss: 0.9511 - val_accuracy: 0.6957\n",
            "Epoch 37/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9299 - accuracy: 0.6634 - val_loss: 0.9598 - val_accuracy: 0.6910\n",
            "Epoch 38/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9258 - accuracy: 0.6698 - val_loss: 0.9117 - val_accuracy: 0.7064\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 39/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9319 - accuracy: 0.6561 - val_loss: 0.9227 - val_accuracy: 0.7177\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 40/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9051 - accuracy: 0.6765 - val_loss: 0.9089 - val_accuracy: 0.7010\n",
            "Epoch 41/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9113 - accuracy: 0.6658 - val_loss: 0.9403 - val_accuracy: 0.6910\n",
            "Epoch 42/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9118 - accuracy: 0.6661 - val_loss: 0.9407 - val_accuracy: 0.7050\n",
            "Epoch 43/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.9095 - accuracy: 0.6698 - val_loss: 0.8948 - val_accuracy: 0.6963\n",
            "Epoch 44/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8885 - accuracy: 0.6721 - val_loss: 0.9397 - val_accuracy: 0.6863\n",
            "Epoch 45/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8899 - accuracy: 0.6771 - val_loss: 0.9214 - val_accuracy: 0.6977\n",
            "Epoch 46/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8665 - accuracy: 0.6842 - val_loss: 0.9354 - val_accuracy: 0.6769\n",
            "Epoch 47/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8749 - accuracy: 0.6735 - val_loss: 0.9450 - val_accuracy: 0.7003\n",
            "Epoch 48/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8683 - accuracy: 0.6848 - val_loss: 0.9008 - val_accuracy: 0.6796\n",
            "Epoch 49/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8716 - accuracy: 0.6785 - val_loss: 0.9009 - val_accuracy: 0.6829\n",
            "Epoch 50/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8520 - accuracy: 0.6882 - val_loss: 0.9008 - val_accuracy: 0.7057\n",
            "Epoch 51/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8488 - accuracy: 0.6835 - val_loss: 0.8795 - val_accuracy: 0.7164\n",
            "Epoch 52/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8513 - accuracy: 0.6838 - val_loss: 0.8747 - val_accuracy: 0.6977\n",
            "Epoch 53/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8602 - accuracy: 0.6869 - val_loss: 0.8521 - val_accuracy: 0.7110\n",
            "Epoch 54/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8326 - accuracy: 0.6912 - val_loss: 0.8799 - val_accuracy: 0.7110\n",
            "Epoch 55/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8291 - accuracy: 0.6895 - val_loss: 0.8898 - val_accuracy: 0.7318\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 56/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8319 - accuracy: 0.6848 - val_loss: 0.8397 - val_accuracy: 0.7371\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 57/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8303 - accuracy: 0.7009 - val_loss: 0.8639 - val_accuracy: 0.7171\n",
            "Epoch 58/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8170 - accuracy: 0.6992 - val_loss: 0.8566 - val_accuracy: 0.7057\n",
            "Epoch 59/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8118 - accuracy: 0.6969 - val_loss: 0.8544 - val_accuracy: 0.7458\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 60/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8077 - accuracy: 0.6999 - val_loss: 0.8730 - val_accuracy: 0.7431\n",
            "Epoch 61/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7949 - accuracy: 0.7160 - val_loss: 0.8351 - val_accuracy: 0.7231\n",
            "Epoch 62/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.8113 - accuracy: 0.7029 - val_loss: 0.8926 - val_accuracy: 0.7217\n",
            "Epoch 63/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7810 - accuracy: 0.7096 - val_loss: 0.8583 - val_accuracy: 0.7371\n",
            "Epoch 64/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7812 - accuracy: 0.7116 - val_loss: 0.8421 - val_accuracy: 0.7331\n",
            "Epoch 65/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7905 - accuracy: 0.7109 - val_loss: 0.8736 - val_accuracy: 0.7177\n",
            "Epoch 66/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7741 - accuracy: 0.7113 - val_loss: 0.8715 - val_accuracy: 0.7231\n",
            "Epoch 67/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7987 - accuracy: 0.7022 - val_loss: 0.8444 - val_accuracy: 0.7465\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 68/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7665 - accuracy: 0.7220 - val_loss: 0.8521 - val_accuracy: 0.7298\n",
            "Epoch 69/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7852 - accuracy: 0.7073 - val_loss: 0.8656 - val_accuracy: 0.7505\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 70/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7709 - accuracy: 0.7163 - val_loss: 0.8436 - val_accuracy: 0.7291\n",
            "Epoch 71/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7645 - accuracy: 0.7150 - val_loss: 0.8450 - val_accuracy: 0.7398\n",
            "Epoch 72/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7856 - accuracy: 0.7076 - val_loss: 0.8885 - val_accuracy: 0.7398\n",
            "Epoch 73/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7492 - accuracy: 0.7173 - val_loss: 0.8391 - val_accuracy: 0.7391\n",
            "Epoch 74/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7590 - accuracy: 0.7146 - val_loss: 0.8634 - val_accuracy: 0.7478\n",
            "Epoch 75/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7439 - accuracy: 0.7230 - val_loss: 0.8930 - val_accuracy: 0.7472\n",
            "Epoch 76/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7586 - accuracy: 0.7216 - val_loss: 0.8470 - val_accuracy: 0.7378\n",
            "Epoch 77/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7412 - accuracy: 0.7190 - val_loss: 0.8418 - val_accuracy: 0.7532\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 78/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7331 - accuracy: 0.7186 - val_loss: 0.8389 - val_accuracy: 0.7498\n",
            "Epoch 79/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7299 - accuracy: 0.7303 - val_loss: 0.8318 - val_accuracy: 0.7512\n",
            "Epoch 80/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7539 - accuracy: 0.7220 - val_loss: 0.8268 - val_accuracy: 0.7525\n",
            "Epoch 81/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7359 - accuracy: 0.7263 - val_loss: 0.8854 - val_accuracy: 0.7686\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 82/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7403 - accuracy: 0.7146 - val_loss: 0.8213 - val_accuracy: 0.7431\n",
            "Epoch 83/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7303 - accuracy: 0.7230 - val_loss: 0.8364 - val_accuracy: 0.7418\n",
            "Epoch 84/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7435 - accuracy: 0.7257 - val_loss: 0.8196 - val_accuracy: 0.7645\n",
            "Epoch 85/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7167 - accuracy: 0.7327 - val_loss: 0.8573 - val_accuracy: 0.7492\n",
            "Epoch 86/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7280 - accuracy: 0.7317 - val_loss: 0.8229 - val_accuracy: 0.7659\n",
            "Epoch 87/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7188 - accuracy: 0.7334 - val_loss: 0.7887 - val_accuracy: 0.7639\n",
            "Epoch 88/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7151 - accuracy: 0.7313 - val_loss: 0.8883 - val_accuracy: 0.7385\n",
            "Epoch 89/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6983 - accuracy: 0.7374 - val_loss: 0.8637 - val_accuracy: 0.7411\n",
            "Epoch 90/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7396 - accuracy: 0.7297 - val_loss: 0.8215 - val_accuracy: 0.7773\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 91/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6991 - accuracy: 0.7364 - val_loss: 0.8322 - val_accuracy: 0.7579\n",
            "Epoch 92/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6927 - accuracy: 0.7414 - val_loss: 0.8163 - val_accuracy: 0.7538\n",
            "Epoch 93/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7175 - accuracy: 0.7313 - val_loss: 0.8402 - val_accuracy: 0.7538\n",
            "Epoch 94/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7231 - accuracy: 0.7384 - val_loss: 0.8304 - val_accuracy: 0.7552\n",
            "Epoch 95/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6908 - accuracy: 0.7421 - val_loss: 0.8542 - val_accuracy: 0.7518\n",
            "Epoch 96/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7085 - accuracy: 0.7330 - val_loss: 0.8842 - val_accuracy: 0.7686\n",
            "Epoch 97/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6799 - accuracy: 0.7491 - val_loss: 0.8528 - val_accuracy: 0.7545\n",
            "Epoch 98/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6908 - accuracy: 0.7384 - val_loss: 0.8513 - val_accuracy: 0.7719\n",
            "Epoch 99/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6726 - accuracy: 0.7394 - val_loss: 0.8588 - val_accuracy: 0.7605\n",
            "Epoch 100/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.7006 - accuracy: 0.7367 - val_loss: 0.8644 - val_accuracy: 0.7579\n",
            "Epoch 101/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6594 - accuracy: 0.7467 - val_loss: 0.8784 - val_accuracy: 0.7612\n",
            "Epoch 102/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6911 - accuracy: 0.7421 - val_loss: 0.8630 - val_accuracy: 0.7692\n",
            "Epoch 103/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6723 - accuracy: 0.7494 - val_loss: 0.8851 - val_accuracy: 0.7599\n",
            "Epoch 104/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6789 - accuracy: 0.7528 - val_loss: 0.8587 - val_accuracy: 0.7579\n",
            "Epoch 105/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6637 - accuracy: 0.7548 - val_loss: 0.8623 - val_accuracy: 0.7579\n",
            "Epoch 106/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6619 - accuracy: 0.7467 - val_loss: 0.8747 - val_accuracy: 0.7686\n",
            "Epoch 107/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6677 - accuracy: 0.7447 - val_loss: 0.8512 - val_accuracy: 0.7592\n",
            "Epoch 108/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6815 - accuracy: 0.7347 - val_loss: 0.8692 - val_accuracy: 0.7719\n",
            "Epoch 109/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6800 - accuracy: 0.7431 - val_loss: 0.9284 - val_accuracy: 0.7645\n",
            "Epoch 110/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6553 - accuracy: 0.7544 - val_loss: 0.9455 - val_accuracy: 0.7692\n",
            "Epoch 111/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6408 - accuracy: 0.7735 - val_loss: 0.9406 - val_accuracy: 0.7585\n",
            "Epoch 112/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6656 - accuracy: 0.7514 - val_loss: 0.9222 - val_accuracy: 0.7612\n",
            "Epoch 113/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6564 - accuracy: 0.7578 - val_loss: 0.8712 - val_accuracy: 0.7659\n",
            "Epoch 114/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6512 - accuracy: 0.7608 - val_loss: 0.8812 - val_accuracy: 0.7625\n",
            "Epoch 115/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6678 - accuracy: 0.7461 - val_loss: 0.9083 - val_accuracy: 0.7639\n",
            "Epoch 116/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6491 - accuracy: 0.7571 - val_loss: 0.9369 - val_accuracy: 0.7759\n",
            "Epoch 117/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6514 - accuracy: 0.7641 - val_loss: 0.9169 - val_accuracy: 0.7579\n",
            "Epoch 118/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6722 - accuracy: 0.7518 - val_loss: 0.8608 - val_accuracy: 0.7525\n",
            "Epoch 119/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6474 - accuracy: 0.7645 - val_loss: 0.8874 - val_accuracy: 0.7492\n",
            "Epoch 120/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6531 - accuracy: 0.7558 - val_loss: 0.9044 - val_accuracy: 0.7732\n",
            "Epoch 121/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6442 - accuracy: 0.7615 - val_loss: 1.0054 - val_accuracy: 0.7726\n",
            "Epoch 122/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6528 - accuracy: 0.7508 - val_loss: 0.9099 - val_accuracy: 0.7659\n",
            "Epoch 123/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6333 - accuracy: 0.7588 - val_loss: 0.9715 - val_accuracy: 0.7639\n",
            "Epoch 124/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6185 - accuracy: 0.7722 - val_loss: 0.9264 - val_accuracy: 0.7585\n",
            "Epoch 125/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6418 - accuracy: 0.7628 - val_loss: 0.8935 - val_accuracy: 0.7679\n",
            "Epoch 126/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6306 - accuracy: 0.7568 - val_loss: 0.8567 - val_accuracy: 0.7605\n",
            "Epoch 127/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6453 - accuracy: 0.7551 - val_loss: 0.8648 - val_accuracy: 0.7592\n",
            "Epoch 128/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6363 - accuracy: 0.7595 - val_loss: 1.0069 - val_accuracy: 0.7659\n",
            "Epoch 129/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6425 - accuracy: 0.7685 - val_loss: 0.9303 - val_accuracy: 0.7639\n",
            "Epoch 130/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6316 - accuracy: 0.7645 - val_loss: 0.9047 - val_accuracy: 0.7732\n",
            "Epoch 131/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6292 - accuracy: 0.7715 - val_loss: 0.9798 - val_accuracy: 0.7565\n",
            "Epoch 132/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6395 - accuracy: 0.7584 - val_loss: 0.9363 - val_accuracy: 0.7732\n",
            "Epoch 133/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6378 - accuracy: 0.7645 - val_loss: 0.9410 - val_accuracy: 0.7860\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 134/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6166 - accuracy: 0.7795 - val_loss: 0.9485 - val_accuracy: 0.7739\n",
            "Epoch 135/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6184 - accuracy: 0.7698 - val_loss: 0.9121 - val_accuracy: 0.7819\n",
            "Epoch 136/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6197 - accuracy: 0.7728 - val_loss: 0.9066 - val_accuracy: 0.7625\n",
            "Epoch 137/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6213 - accuracy: 0.7742 - val_loss: 0.9394 - val_accuracy: 0.7666\n",
            "Epoch 138/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6081 - accuracy: 0.7695 - val_loss: 0.9151 - val_accuracy: 0.7759\n",
            "Epoch 139/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6340 - accuracy: 0.7681 - val_loss: 0.9101 - val_accuracy: 0.7759\n",
            "Epoch 140/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6154 - accuracy: 0.7705 - val_loss: 0.9765 - val_accuracy: 0.7873\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 141/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6161 - accuracy: 0.7758 - val_loss: 0.9555 - val_accuracy: 0.7846\n",
            "Epoch 142/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6180 - accuracy: 0.7645 - val_loss: 0.9824 - val_accuracy: 0.7732\n",
            "Epoch 143/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5991 - accuracy: 0.7785 - val_loss: 0.9346 - val_accuracy: 0.7819\n",
            "Epoch 144/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6140 - accuracy: 0.7732 - val_loss: 1.0413 - val_accuracy: 0.7773\n",
            "Epoch 145/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5881 - accuracy: 0.7842 - val_loss: 1.0246 - val_accuracy: 0.7659\n",
            "Epoch 146/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6137 - accuracy: 0.7782 - val_loss: 0.9929 - val_accuracy: 0.7786\n",
            "Epoch 147/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6022 - accuracy: 0.7779 - val_loss: 0.9281 - val_accuracy: 0.7679\n",
            "Epoch 148/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5979 - accuracy: 0.7822 - val_loss: 0.9211 - val_accuracy: 0.7799\n",
            "Epoch 149/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6203 - accuracy: 0.7728 - val_loss: 0.9555 - val_accuracy: 0.7813\n",
            "Epoch 150/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6169 - accuracy: 0.7702 - val_loss: 0.9777 - val_accuracy: 0.7779\n",
            "Epoch 151/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5967 - accuracy: 0.7805 - val_loss: 0.9050 - val_accuracy: 0.7880\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 152/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5826 - accuracy: 0.7795 - val_loss: 0.9369 - val_accuracy: 0.7813\n",
            "Epoch 153/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5852 - accuracy: 0.7852 - val_loss: 1.0399 - val_accuracy: 0.7826\n",
            "Epoch 154/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5839 - accuracy: 0.7936 - val_loss: 0.9694 - val_accuracy: 0.7793\n",
            "Epoch 155/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5922 - accuracy: 0.7768 - val_loss: 1.0065 - val_accuracy: 0.7726\n",
            "Epoch 156/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5747 - accuracy: 0.7922 - val_loss: 0.9727 - val_accuracy: 0.7766\n",
            "Epoch 157/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5997 - accuracy: 0.7758 - val_loss: 1.0321 - val_accuracy: 0.7779\n",
            "Epoch 158/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.6029 - accuracy: 0.7755 - val_loss: 0.9756 - val_accuracy: 0.7926\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 159/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5876 - accuracy: 0.7862 - val_loss: 1.0061 - val_accuracy: 0.7753\n",
            "Epoch 160/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5784 - accuracy: 0.7835 - val_loss: 0.9822 - val_accuracy: 0.7819\n",
            "Epoch 161/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5824 - accuracy: 0.7902 - val_loss: 1.0840 - val_accuracy: 0.7719\n",
            "Epoch 162/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5738 - accuracy: 0.7859 - val_loss: 0.9614 - val_accuracy: 0.7793\n",
            "Epoch 163/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5603 - accuracy: 0.7879 - val_loss: 0.9224 - val_accuracy: 0.7719\n",
            "Epoch 164/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5556 - accuracy: 0.7882 - val_loss: 0.9969 - val_accuracy: 0.7786\n",
            "Epoch 165/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5808 - accuracy: 0.7772 - val_loss: 1.0096 - val_accuracy: 0.7679\n",
            "Epoch 166/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5633 - accuracy: 0.7922 - val_loss: 1.0930 - val_accuracy: 0.7860\n",
            "Epoch 167/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5823 - accuracy: 0.7842 - val_loss: 1.0845 - val_accuracy: 0.7813\n",
            "Epoch 168/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5694 - accuracy: 0.7876 - val_loss: 1.0572 - val_accuracy: 0.7739\n",
            "Epoch 169/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5719 - accuracy: 0.7882 - val_loss: 0.9403 - val_accuracy: 0.7773\n",
            "Epoch 170/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5694 - accuracy: 0.7949 - val_loss: 0.9627 - val_accuracy: 0.7759\n",
            "Epoch 171/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5853 - accuracy: 0.7822 - val_loss: 1.1041 - val_accuracy: 0.7913\n",
            "Epoch 172/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5662 - accuracy: 0.7882 - val_loss: 1.1039 - val_accuracy: 0.7920\n",
            "Epoch 173/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5573 - accuracy: 0.7942 - val_loss: 0.9805 - val_accuracy: 0.7739\n",
            "Epoch 174/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5784 - accuracy: 0.7942 - val_loss: 0.9714 - val_accuracy: 0.7973\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 175/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5735 - accuracy: 0.7959 - val_loss: 0.9900 - val_accuracy: 0.7806\n",
            "Epoch 176/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5563 - accuracy: 0.7939 - val_loss: 1.1128 - val_accuracy: 0.7906\n",
            "Epoch 177/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5570 - accuracy: 0.7976 - val_loss: 1.0242 - val_accuracy: 0.7913\n",
            "Epoch 178/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5628 - accuracy: 0.7969 - val_loss: 1.0675 - val_accuracy: 0.7926\n",
            "Epoch 179/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5571 - accuracy: 0.7973 - val_loss: 1.0376 - val_accuracy: 0.7926\n",
            "Epoch 180/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5566 - accuracy: 0.7959 - val_loss: 1.0020 - val_accuracy: 0.7860\n",
            "Epoch 181/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5747 - accuracy: 0.7882 - val_loss: 1.0296 - val_accuracy: 0.7866\n",
            "Epoch 182/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5434 - accuracy: 0.8006 - val_loss: 1.1370 - val_accuracy: 0.7799\n",
            "Epoch 183/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5583 - accuracy: 0.8056 - val_loss: 0.9680 - val_accuracy: 0.7886\n",
            "Epoch 184/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5455 - accuracy: 0.7912 - val_loss: 1.0098 - val_accuracy: 0.7759\n",
            "Epoch 185/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5462 - accuracy: 0.7996 - val_loss: 0.9894 - val_accuracy: 0.7826\n",
            "Epoch 186/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5450 - accuracy: 0.7969 - val_loss: 1.0370 - val_accuracy: 0.7739\n",
            "Epoch 187/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5431 - accuracy: 0.7963 - val_loss: 1.1025 - val_accuracy: 0.7773\n",
            "Epoch 188/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5290 - accuracy: 0.7989 - val_loss: 1.1477 - val_accuracy: 0.7806\n",
            "Epoch 189/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5389 - accuracy: 0.8046 - val_loss: 1.0389 - val_accuracy: 0.7866\n",
            "Epoch 190/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5158 - accuracy: 0.8023 - val_loss: 1.1064 - val_accuracy: 0.7786\n",
            "Epoch 191/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5521 - accuracy: 0.8013 - val_loss: 1.0246 - val_accuracy: 0.7860\n",
            "Epoch 192/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5252 - accuracy: 0.8056 - val_loss: 1.1291 - val_accuracy: 0.7880\n",
            "Epoch 193/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5133 - accuracy: 0.8103 - val_loss: 1.0816 - val_accuracy: 0.7913\n",
            "Epoch 194/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5142 - accuracy: 0.8126 - val_loss: 1.1419 - val_accuracy: 0.7953\n",
            "Epoch 195/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5370 - accuracy: 0.8043 - val_loss: 1.0992 - val_accuracy: 0.7826\n",
            "Epoch 196/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5408 - accuracy: 0.7963 - val_loss: 1.0858 - val_accuracy: 0.7813\n",
            "Epoch 197/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5192 - accuracy: 0.8076 - val_loss: 1.1012 - val_accuracy: 0.7846\n",
            "Epoch 198/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5401 - accuracy: 0.8073 - val_loss: 1.1305 - val_accuracy: 0.7953\n",
            "Epoch 199/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5300 - accuracy: 0.8013 - val_loss: 1.1119 - val_accuracy: 0.7893\n",
            "Epoch 200/200\n",
            "2989/2989 [==============================] - 4s 1ms/step - loss: 0.5459 - accuracy: 0.8060 - val_loss: 1.0044 - val_accuracy: 0.7973\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Confusion matrix - Test\n",
            "[[180   0   0   9  11   2   9  25]\n",
            " [  5  17   0   1   0   0   1  18]\n",
            " [  5   0  48   0   0   3   0   2]\n",
            " [ 24   0   0  85   3   1   3  30]\n",
            " [ 36   4   0   1 113   0   2   1]\n",
            " [ 16   1   0   0   0  74   1   5]\n",
            " [ 24   0   0   2   2   1  75   9]\n",
            " [ 13   0   0  23   0   3   7 600]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  California       0.59      0.76      0.67       236\n",
            " Connecticut       0.77      0.40      0.53        42\n",
            "     Florida       1.00      0.83      0.91        58\n",
            "Masachusetts       0.70      0.58      0.64       146\n",
            "    Michigan       0.88      0.72      0.79       157\n",
            "    New York       0.88      0.76      0.82        97\n",
            "    Virginia       0.77      0.66      0.71       113\n",
            "  Washington       0.87      0.93      0.90       646\n",
            "\n",
            "    accuracy                           0.80      1495\n",
            "   macro avg       0.81      0.71      0.74      1495\n",
            "weighted avg       0.81      0.80      0.80      1495\n",
            "\n",
            "Score for fold 2: loss of 1.004371792097953; accuracy of 79.73244190216064%\n",
            "------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Train on 2990 samples, validate on 1494 samples\n",
            "Epoch 1/200\n",
            "2990/2990 [==============================] - 5s 2ms/step - loss: 1.8763 - accuracy: 0.3605 - val_loss: 1.6787 - val_accuracy: 0.4230\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 2/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.7053 - accuracy: 0.4271 - val_loss: 1.5680 - val_accuracy: 0.4230\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 3/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.5548 - accuracy: 0.4836 - val_loss: 1.3030 - val_accuracy: 0.5696\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 4/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.4494 - accuracy: 0.5067 - val_loss: 1.3019 - val_accuracy: 0.5957\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 5/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.3967 - accuracy: 0.5151 - val_loss: 1.2197 - val_accuracy: 0.6084\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 6/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.3751 - accuracy: 0.5211 - val_loss: 1.1175 - val_accuracy: 0.6084\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 7/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.2974 - accuracy: 0.5548 - val_loss: 1.1291 - val_accuracy: 0.6091\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 8/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.2907 - accuracy: 0.5652 - val_loss: 1.0564 - val_accuracy: 0.6406\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 9/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.2545 - accuracy: 0.5692 - val_loss: 1.0413 - val_accuracy: 0.6673\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 10/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.1921 - accuracy: 0.6030 - val_loss: 0.9799 - val_accuracy: 0.6580\n",
            "Epoch 11/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.1688 - accuracy: 0.5906 - val_loss: 0.9492 - val_accuracy: 0.6787\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 12/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.1191 - accuracy: 0.6067 - val_loss: 0.9359 - val_accuracy: 0.6767\n",
            "Epoch 13/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.0818 - accuracy: 0.6214 - val_loss: 0.9429 - val_accuracy: 0.6754\n",
            "Epoch 14/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.0769 - accuracy: 0.6398 - val_loss: 0.9201 - val_accuracy: 0.6847\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 15/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.0672 - accuracy: 0.6227 - val_loss: 0.9654 - val_accuracy: 0.6633\n",
            "Epoch 16/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.0546 - accuracy: 0.6331 - val_loss: 0.8919 - val_accuracy: 0.6908\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 17/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.0218 - accuracy: 0.6435 - val_loss: 0.9389 - val_accuracy: 0.6620\n",
            "Epoch 18/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 1.0024 - accuracy: 0.6482 - val_loss: 0.8853 - val_accuracy: 0.7041\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 19/200\n",
            "2990/2990 [==============================] - 4s 2ms/step - loss: 0.9862 - accuracy: 0.6542 - val_loss: 0.9036 - val_accuracy: 0.6801\n",
            "Epoch 20/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9870 - accuracy: 0.6532 - val_loss: 0.9126 - val_accuracy: 0.6948\n",
            "Epoch 21/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9741 - accuracy: 0.6582 - val_loss: 0.8916 - val_accuracy: 0.6988\n",
            "Epoch 22/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9528 - accuracy: 0.6656 - val_loss: 0.8756 - val_accuracy: 0.7008\n",
            "Epoch 23/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9618 - accuracy: 0.6575 - val_loss: 0.8622 - val_accuracy: 0.7115\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 24/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9593 - accuracy: 0.6659 - val_loss: 0.8777 - val_accuracy: 0.6975\n",
            "Epoch 25/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9484 - accuracy: 0.6649 - val_loss: 0.8597 - val_accuracy: 0.7068\n",
            "Epoch 26/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9270 - accuracy: 0.6779 - val_loss: 0.8799 - val_accuracy: 0.6975\n",
            "Epoch 27/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9090 - accuracy: 0.6843 - val_loss: 0.8948 - val_accuracy: 0.6921\n",
            "Epoch 28/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.9170 - accuracy: 0.6682 - val_loss: 0.8665 - val_accuracy: 0.7149\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 29/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8950 - accuracy: 0.6819 - val_loss: 0.8849 - val_accuracy: 0.7095\n",
            "Epoch 30/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8951 - accuracy: 0.6709 - val_loss: 0.8664 - val_accuracy: 0.7041\n",
            "Epoch 31/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8919 - accuracy: 0.6809 - val_loss: 0.9063 - val_accuracy: 0.6941\n",
            "Epoch 32/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8626 - accuracy: 0.6880 - val_loss: 0.8611 - val_accuracy: 0.7162\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 33/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8624 - accuracy: 0.6896 - val_loss: 0.8995 - val_accuracy: 0.6975\n",
            "Epoch 34/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8677 - accuracy: 0.6896 - val_loss: 0.8802 - val_accuracy: 0.6934\n",
            "Epoch 35/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8534 - accuracy: 0.6893 - val_loss: 0.8717 - val_accuracy: 0.7149\n",
            "Epoch 36/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8542 - accuracy: 0.6926 - val_loss: 0.8901 - val_accuracy: 0.7108\n",
            "Epoch 37/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8597 - accuracy: 0.6890 - val_loss: 0.8728 - val_accuracy: 0.7209\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 38/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8410 - accuracy: 0.6973 - val_loss: 0.8786 - val_accuracy: 0.7276\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 39/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8237 - accuracy: 0.7050 - val_loss: 0.8962 - val_accuracy: 0.7236\n",
            "Epoch 40/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8377 - accuracy: 0.6916 - val_loss: 0.8814 - val_accuracy: 0.7195\n",
            "Epoch 41/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8249 - accuracy: 0.7047 - val_loss: 0.9017 - val_accuracy: 0.7269\n",
            "Epoch 42/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8141 - accuracy: 0.7040 - val_loss: 0.8398 - val_accuracy: 0.7363\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 43/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.8175 - accuracy: 0.6997 - val_loss: 0.8763 - val_accuracy: 0.7062\n",
            "Epoch 44/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7932 - accuracy: 0.7080 - val_loss: 0.8714 - val_accuracy: 0.7376\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 45/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7895 - accuracy: 0.7097 - val_loss: 0.8809 - val_accuracy: 0.7303\n",
            "Epoch 46/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7872 - accuracy: 0.7017 - val_loss: 0.8990 - val_accuracy: 0.7122\n",
            "Epoch 47/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7973 - accuracy: 0.7037 - val_loss: 0.8922 - val_accuracy: 0.7356\n",
            "Epoch 48/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7845 - accuracy: 0.7107 - val_loss: 0.8890 - val_accuracy: 0.7416\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 49/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7659 - accuracy: 0.7201 - val_loss: 0.8440 - val_accuracy: 0.7390\n",
            "Epoch 50/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7737 - accuracy: 0.7164 - val_loss: 0.9038 - val_accuracy: 0.7436\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 51/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7554 - accuracy: 0.7201 - val_loss: 0.9348 - val_accuracy: 0.7470\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 52/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7686 - accuracy: 0.7074 - val_loss: 0.9132 - val_accuracy: 0.7430\n",
            "Epoch 53/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7521 - accuracy: 0.7171 - val_loss: 0.8794 - val_accuracy: 0.7363\n",
            "Epoch 54/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7488 - accuracy: 0.7241 - val_loss: 0.8801 - val_accuracy: 0.7530\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 55/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7433 - accuracy: 0.7258 - val_loss: 0.9535 - val_accuracy: 0.7336\n",
            "Epoch 56/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7558 - accuracy: 0.7211 - val_loss: 0.9302 - val_accuracy: 0.7343\n",
            "Epoch 57/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7352 - accuracy: 0.7281 - val_loss: 0.9120 - val_accuracy: 0.7490\n",
            "Epoch 58/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7360 - accuracy: 0.7291 - val_loss: 0.9467 - val_accuracy: 0.7570\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 59/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7328 - accuracy: 0.7254 - val_loss: 0.9387 - val_accuracy: 0.7483\n",
            "Epoch 60/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7238 - accuracy: 0.7284 - val_loss: 0.9607 - val_accuracy: 0.7456\n",
            "Epoch 61/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7288 - accuracy: 0.7284 - val_loss: 0.9609 - val_accuracy: 0.7490\n",
            "Epoch 62/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7053 - accuracy: 0.7418 - val_loss: 0.9381 - val_accuracy: 0.7497\n",
            "Epoch 63/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7121 - accuracy: 0.7348 - val_loss: 0.9133 - val_accuracy: 0.7617\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 64/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7131 - accuracy: 0.7381 - val_loss: 0.9702 - val_accuracy: 0.7564\n",
            "Epoch 65/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7066 - accuracy: 0.7435 - val_loss: 0.8958 - val_accuracy: 0.7450\n",
            "Epoch 66/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6899 - accuracy: 0.7371 - val_loss: 0.9464 - val_accuracy: 0.7450\n",
            "Epoch 67/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7026 - accuracy: 0.7415 - val_loss: 0.9160 - val_accuracy: 0.7584\n",
            "Epoch 68/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.7026 - accuracy: 0.7431 - val_loss: 0.9221 - val_accuracy: 0.7584\n",
            "Epoch 69/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6841 - accuracy: 0.7495 - val_loss: 0.9610 - val_accuracy: 0.7517\n",
            "Epoch 70/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6801 - accuracy: 0.7505 - val_loss: 1.0227 - val_accuracy: 0.7544\n",
            "Epoch 71/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6775 - accuracy: 0.7458 - val_loss: 0.9393 - val_accuracy: 0.7490\n",
            "Epoch 72/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6794 - accuracy: 0.7452 - val_loss: 0.9985 - val_accuracy: 0.7564\n",
            "Epoch 73/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6975 - accuracy: 0.7415 - val_loss: 0.9218 - val_accuracy: 0.7544\n",
            "Epoch 74/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6767 - accuracy: 0.7502 - val_loss: 0.9961 - val_accuracy: 0.7590\n",
            "Epoch 75/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6707 - accuracy: 0.7488 - val_loss: 0.9457 - val_accuracy: 0.7537\n",
            "Epoch 76/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6695 - accuracy: 0.7502 - val_loss: 0.9301 - val_accuracy: 0.7530\n",
            "Epoch 77/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6692 - accuracy: 0.7478 - val_loss: 0.9479 - val_accuracy: 0.7470\n",
            "Epoch 78/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6682 - accuracy: 0.7548 - val_loss: 0.9400 - val_accuracy: 0.7564\n",
            "Epoch 79/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6546 - accuracy: 0.7609 - val_loss: 1.0011 - val_accuracy: 0.7390\n",
            "Epoch 80/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6550 - accuracy: 0.7545 - val_loss: 1.0009 - val_accuracy: 0.7704\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 81/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6390 - accuracy: 0.7629 - val_loss: 0.9506 - val_accuracy: 0.7503\n",
            "Epoch 82/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6336 - accuracy: 0.7696 - val_loss: 0.9372 - val_accuracy: 0.7711\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 83/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6548 - accuracy: 0.7625 - val_loss: 0.9389 - val_accuracy: 0.7711\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 84/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6415 - accuracy: 0.7652 - val_loss: 1.0276 - val_accuracy: 0.7597\n",
            "Epoch 85/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6199 - accuracy: 0.7729 - val_loss: 0.9682 - val_accuracy: 0.7704\n",
            "Epoch 86/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6538 - accuracy: 0.7525 - val_loss: 0.9883 - val_accuracy: 0.7771\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 87/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6312 - accuracy: 0.7652 - val_loss: 1.0006 - val_accuracy: 0.7744\n",
            "Epoch 88/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6243 - accuracy: 0.7689 - val_loss: 0.9377 - val_accuracy: 0.7738\n",
            "Epoch 89/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6200 - accuracy: 0.7766 - val_loss: 1.0374 - val_accuracy: 0.7671\n",
            "Epoch 90/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6281 - accuracy: 0.7702 - val_loss: 0.9663 - val_accuracy: 0.7718\n",
            "Epoch 91/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6042 - accuracy: 0.7769 - val_loss: 1.0675 - val_accuracy: 0.7778\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 92/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6035 - accuracy: 0.7819 - val_loss: 1.0021 - val_accuracy: 0.7798\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 93/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6018 - accuracy: 0.7846 - val_loss: 0.9292 - val_accuracy: 0.7557\n",
            "Epoch 94/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5990 - accuracy: 0.7789 - val_loss: 1.0059 - val_accuracy: 0.7751\n",
            "Epoch 95/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5876 - accuracy: 0.7866 - val_loss: 1.0216 - val_accuracy: 0.7751\n",
            "Epoch 96/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5981 - accuracy: 0.7799 - val_loss: 1.1087 - val_accuracy: 0.7791\n",
            "Epoch 97/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5868 - accuracy: 0.7809 - val_loss: 1.0311 - val_accuracy: 0.7811\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 98/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5905 - accuracy: 0.7883 - val_loss: 0.9563 - val_accuracy: 0.7751\n",
            "Epoch 99/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5904 - accuracy: 0.7933 - val_loss: 1.0367 - val_accuracy: 0.7898\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 100/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.6009 - accuracy: 0.7823 - val_loss: 1.0319 - val_accuracy: 0.7691\n",
            "Epoch 101/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5880 - accuracy: 0.7943 - val_loss: 1.0111 - val_accuracy: 0.7764\n",
            "Epoch 102/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5761 - accuracy: 0.7906 - val_loss: 0.9902 - val_accuracy: 0.7758\n",
            "Epoch 103/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5624 - accuracy: 0.7930 - val_loss: 1.0017 - val_accuracy: 0.7771\n",
            "Epoch 104/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5751 - accuracy: 0.7933 - val_loss: 0.9333 - val_accuracy: 0.7691\n",
            "Epoch 105/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5635 - accuracy: 0.8037 - val_loss: 0.9809 - val_accuracy: 0.7811\n",
            "Epoch 106/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5644 - accuracy: 0.7906 - val_loss: 1.0061 - val_accuracy: 0.7865\n",
            "Epoch 107/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5527 - accuracy: 0.7903 - val_loss: 1.2459 - val_accuracy: 0.7744\n",
            "Epoch 108/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5373 - accuracy: 0.8040 - val_loss: 1.0337 - val_accuracy: 0.7771\n",
            "Epoch 109/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5766 - accuracy: 0.7896 - val_loss: 0.9750 - val_accuracy: 0.7838\n",
            "Epoch 110/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5604 - accuracy: 0.7953 - val_loss: 1.0148 - val_accuracy: 0.7778\n",
            "Epoch 111/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5462 - accuracy: 0.8094 - val_loss: 0.9787 - val_accuracy: 0.7878\n",
            "Epoch 112/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5416 - accuracy: 0.7957 - val_loss: 1.0152 - val_accuracy: 0.7892\n",
            "Epoch 113/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5340 - accuracy: 0.8077 - val_loss: 1.0093 - val_accuracy: 0.7805\n",
            "Epoch 114/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5555 - accuracy: 0.7900 - val_loss: 0.9760 - val_accuracy: 0.7831\n",
            "Epoch 115/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5341 - accuracy: 0.7980 - val_loss: 1.0736 - val_accuracy: 0.7932\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 116/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5322 - accuracy: 0.8090 - val_loss: 1.0983 - val_accuracy: 0.7925\n",
            "Epoch 117/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5372 - accuracy: 0.8107 - val_loss: 1.1399 - val_accuracy: 0.7912\n",
            "Epoch 118/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5202 - accuracy: 0.8157 - val_loss: 1.0288 - val_accuracy: 0.7851\n",
            "Epoch 119/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5333 - accuracy: 0.8164 - val_loss: 1.1006 - val_accuracy: 0.7885\n",
            "Epoch 120/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5257 - accuracy: 0.8003 - val_loss: 1.0945 - val_accuracy: 0.7912\n",
            "Epoch 121/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5368 - accuracy: 0.8057 - val_loss: 1.1589 - val_accuracy: 0.7932\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 122/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5061 - accuracy: 0.8110 - val_loss: 1.1589 - val_accuracy: 0.7912\n",
            "Epoch 123/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5261 - accuracy: 0.8110 - val_loss: 1.1238 - val_accuracy: 0.7885\n",
            "Epoch 124/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5069 - accuracy: 0.8194 - val_loss: 1.1604 - val_accuracy: 0.7925\n",
            "Epoch 125/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5264 - accuracy: 0.8060 - val_loss: 1.1026 - val_accuracy: 0.7871\n",
            "Epoch 126/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5308 - accuracy: 0.8107 - val_loss: 1.1494 - val_accuracy: 0.7878\n",
            "Epoch 127/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5008 - accuracy: 0.8140 - val_loss: 1.0728 - val_accuracy: 0.7945\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 128/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4959 - accuracy: 0.8258 - val_loss: 1.1251 - val_accuracy: 0.7938\n",
            "Epoch 129/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5068 - accuracy: 0.8221 - val_loss: 1.0647 - val_accuracy: 0.7878\n",
            "Epoch 130/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5008 - accuracy: 0.8227 - val_loss: 1.0839 - val_accuracy: 0.7778\n",
            "Epoch 131/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5132 - accuracy: 0.8117 - val_loss: 1.0032 - val_accuracy: 0.7764\n",
            "Epoch 132/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4966 - accuracy: 0.8177 - val_loss: 1.0527 - val_accuracy: 0.7865\n",
            "Epoch 133/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4907 - accuracy: 0.8174 - val_loss: 1.0494 - val_accuracy: 0.7992\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 134/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4994 - accuracy: 0.8197 - val_loss: 1.0073 - val_accuracy: 0.7965\n",
            "Epoch 135/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.5074 - accuracy: 0.8184 - val_loss: 1.0501 - val_accuracy: 0.7811\n",
            "Epoch 136/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4984 - accuracy: 0.8261 - val_loss: 1.0562 - val_accuracy: 0.7845\n",
            "Epoch 137/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4998 - accuracy: 0.8251 - val_loss: 1.0316 - val_accuracy: 0.7825\n",
            "Epoch 138/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4708 - accuracy: 0.8251 - val_loss: 1.1082 - val_accuracy: 0.7979\n",
            "Epoch 139/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4860 - accuracy: 0.8368 - val_loss: 1.1505 - val_accuracy: 0.7972\n",
            "Epoch 140/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4976 - accuracy: 0.8211 - val_loss: 1.1809 - val_accuracy: 0.8039\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 141/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4917 - accuracy: 0.8278 - val_loss: 1.1009 - val_accuracy: 0.7965\n",
            "Epoch 142/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4904 - accuracy: 0.8241 - val_loss: 1.1721 - val_accuracy: 0.7932\n",
            "Epoch 143/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4876 - accuracy: 0.8251 - val_loss: 1.1277 - val_accuracy: 0.7905\n",
            "Epoch 144/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4814 - accuracy: 0.8214 - val_loss: 1.1027 - val_accuracy: 0.7965\n",
            "Epoch 145/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4853 - accuracy: 0.8284 - val_loss: 1.0521 - val_accuracy: 0.8005\n",
            "Epoch 146/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4837 - accuracy: 0.8194 - val_loss: 1.1087 - val_accuracy: 0.8025\n",
            "Epoch 147/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4717 - accuracy: 0.8351 - val_loss: 1.0899 - val_accuracy: 0.7999\n",
            "Epoch 148/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4807 - accuracy: 0.8261 - val_loss: 1.0861 - val_accuracy: 0.7972\n",
            "Epoch 149/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4860 - accuracy: 0.8224 - val_loss: 1.0628 - val_accuracy: 0.7932\n",
            "Epoch 150/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4642 - accuracy: 0.8321 - val_loss: 1.1331 - val_accuracy: 0.7959\n",
            "Epoch 151/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4704 - accuracy: 0.8348 - val_loss: 1.1817 - val_accuracy: 0.8025\n",
            "Epoch 152/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4559 - accuracy: 0.8294 - val_loss: 1.1660 - val_accuracy: 0.8072\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 153/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4436 - accuracy: 0.8431 - val_loss: 1.1460 - val_accuracy: 0.8059\n",
            "Epoch 154/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4727 - accuracy: 0.8351 - val_loss: 1.2196 - val_accuracy: 0.8099\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 155/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4728 - accuracy: 0.8321 - val_loss: 1.0971 - val_accuracy: 0.7999\n",
            "Epoch 156/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4746 - accuracy: 0.8334 - val_loss: 1.1362 - val_accuracy: 0.8025\n",
            "Epoch 157/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4664 - accuracy: 0.8371 - val_loss: 1.0486 - val_accuracy: 0.7858\n",
            "Epoch 158/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4554 - accuracy: 0.8371 - val_loss: 1.1239 - val_accuracy: 0.7992\n",
            "Epoch 159/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4524 - accuracy: 0.8365 - val_loss: 1.1640 - val_accuracy: 0.8039\n",
            "Epoch 160/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4519 - accuracy: 0.8368 - val_loss: 1.1996 - val_accuracy: 0.8012\n",
            "Epoch 161/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4402 - accuracy: 0.8482 - val_loss: 1.2069 - val_accuracy: 0.8005\n",
            "Epoch 162/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4474 - accuracy: 0.8375 - val_loss: 1.1759 - val_accuracy: 0.7999\n",
            "Epoch 163/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4418 - accuracy: 0.8425 - val_loss: 1.1388 - val_accuracy: 0.7999\n",
            "Epoch 164/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4398 - accuracy: 0.8468 - val_loss: 1.1937 - val_accuracy: 0.7992\n",
            "Epoch 165/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4737 - accuracy: 0.8261 - val_loss: 1.2213 - val_accuracy: 0.8032\n",
            "Epoch 166/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4518 - accuracy: 0.8455 - val_loss: 1.1429 - val_accuracy: 0.7972\n",
            "Epoch 167/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4458 - accuracy: 0.8401 - val_loss: 1.2374 - val_accuracy: 0.7985\n",
            "Epoch 168/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4418 - accuracy: 0.8388 - val_loss: 1.2153 - val_accuracy: 0.8112\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 169/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4345 - accuracy: 0.8468 - val_loss: 1.2396 - val_accuracy: 0.7985\n",
            "Epoch 170/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4290 - accuracy: 0.8468 - val_loss: 1.2553 - val_accuracy: 0.8099\n",
            "Epoch 171/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4390 - accuracy: 0.8441 - val_loss: 1.2796 - val_accuracy: 0.8005\n",
            "Epoch 172/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4308 - accuracy: 0.8505 - val_loss: 1.2765 - val_accuracy: 0.8039\n",
            "Epoch 173/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4361 - accuracy: 0.8421 - val_loss: 1.2513 - val_accuracy: 0.7992\n",
            "Epoch 174/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4340 - accuracy: 0.8431 - val_loss: 1.2286 - val_accuracy: 0.7985\n",
            "Epoch 175/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4327 - accuracy: 0.8492 - val_loss: 1.2391 - val_accuracy: 0.8092\n",
            "Epoch 176/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4219 - accuracy: 0.8381 - val_loss: 1.3716 - val_accuracy: 0.8032\n",
            "Epoch 177/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4480 - accuracy: 0.8415 - val_loss: 1.3224 - val_accuracy: 0.7965\n",
            "Epoch 178/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4398 - accuracy: 0.8478 - val_loss: 1.2878 - val_accuracy: 0.8025\n",
            "Epoch 179/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4305 - accuracy: 0.8468 - val_loss: 1.3106 - val_accuracy: 0.8126\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 180/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4201 - accuracy: 0.8512 - val_loss: 1.3644 - val_accuracy: 0.8025\n",
            "Epoch 181/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4303 - accuracy: 0.8478 - val_loss: 1.3352 - val_accuracy: 0.8086\n",
            "Epoch 182/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4033 - accuracy: 0.8508 - val_loss: 1.3002 - val_accuracy: 0.8072\n",
            "Epoch 183/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4029 - accuracy: 0.8599 - val_loss: 1.3664 - val_accuracy: 0.7979\n",
            "Epoch 184/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4351 - accuracy: 0.8431 - val_loss: 1.4905 - val_accuracy: 0.8059\n",
            "Epoch 185/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4285 - accuracy: 0.8548 - val_loss: 1.2576 - val_accuracy: 0.8086\n",
            "Epoch 186/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4144 - accuracy: 0.8562 - val_loss: 1.1990 - val_accuracy: 0.8066\n",
            "Epoch 187/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.3867 - accuracy: 0.8615 - val_loss: 1.2647 - val_accuracy: 0.8039\n",
            "Epoch 188/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4094 - accuracy: 0.8538 - val_loss: 1.2337 - val_accuracy: 0.8046\n",
            "Epoch 189/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4147 - accuracy: 0.8528 - val_loss: 1.1995 - val_accuracy: 0.8086\n",
            "Epoch 190/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4156 - accuracy: 0.8515 - val_loss: 1.4908 - val_accuracy: 0.7992\n",
            "Epoch 191/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4083 - accuracy: 0.8555 - val_loss: 1.3155 - val_accuracy: 0.8092\n",
            "Epoch 192/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4102 - accuracy: 0.8595 - val_loss: 1.2900 - val_accuracy: 0.8032\n",
            "Epoch 193/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4054 - accuracy: 0.8515 - val_loss: 1.5768 - val_accuracy: 0.8119\n",
            "Epoch 194/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4140 - accuracy: 0.8535 - val_loss: 1.3135 - val_accuracy: 0.8032\n",
            "Epoch 195/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4128 - accuracy: 0.8572 - val_loss: 1.3692 - val_accuracy: 0.7992\n",
            "Epoch 196/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.3867 - accuracy: 0.8572 - val_loss: 1.4129 - val_accuracy: 0.7985\n",
            "Epoch 197/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4205 - accuracy: 0.8505 - val_loss: 1.4154 - val_accuracy: 0.8092\n",
            "Epoch 198/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.4178 - accuracy: 0.8508 - val_loss: 1.3747 - val_accuracy: 0.8005\n",
            "Epoch 199/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.3979 - accuracy: 0.8572 - val_loss: 1.4748 - val_accuracy: 0.8086\n",
            "Epoch 200/200\n",
            "2990/2990 [==============================] - 4s 1ms/step - loss: 0.3953 - accuracy: 0.8582 - val_loss: 1.4886 - val_accuracy: 0.8005\n",
            "Confusion matrix - Test\n",
            "[[174   2   3   6  21   2  15  17]\n",
            " [  3  15   0   1   1   1   0  12]\n",
            " [  2   0  39   0   0   2   0   2]\n",
            " [ 10   0   0  97   1   0   3  26]\n",
            " [ 22   5   1   4 144   0   2   0]\n",
            " [  7   3   0   5   0  85   1   8]\n",
            " [ 15   1   0   7   2   2  78  15]\n",
            " [ 20   4   3  18   2   0   3 582]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  California       0.69      0.72      0.71       240\n",
            " Connecticut       0.50      0.45      0.48        33\n",
            "     Florida       0.85      0.87      0.86        45\n",
            "Masachusetts       0.70      0.71      0.71       137\n",
            "    Michigan       0.84      0.81      0.83       178\n",
            "    New York       0.92      0.78      0.85       109\n",
            "    Virginia       0.76      0.65      0.70       120\n",
            "  Washington       0.88      0.92      0.90       632\n",
            "\n",
            "    accuracy                           0.81      1494\n",
            "   macro avg       0.77      0.74      0.75      1494\n",
            "weighted avg       0.81      0.81      0.81      1494\n",
            "\n",
            "Score for fold 3: loss of 1.3106435860047139; accuracy of 81.25836849212646%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f1V3XzqXDyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "a93473ec-4bb4-4802-bcbd-19329b831956"
      },
      "source": [
        "print('------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(cvscores)):\n",
        "  print('-----------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {cvscores[i]}%')\n",
        "print('--------------------------------------------------')\n",
        "print('Average score for all folds:')\n",
        "print(f'> Accuracy: {np.mean(cvscores)}')\n",
        "print(f'>Loss: {np.mean(loss_per_fold)}')\n",
        "#print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------\n",
            "Score per fold\n",
            "-----------------------------------------------------\n",
            "> Fold 1 - Loss: 1.3297190999107615 - Accuracy: 80.73578476905823%\n",
            "-----------------------------------------------------\n",
            "> Fold 2 - Loss: 1.395339061588946 - Accuracy: 80.13377785682678%\n",
            "-----------------------------------------------------\n",
            "> Fold 3 - Loss: 1.2593145533358876 - Accuracy: 76.03748440742493%\n",
            "--------------------------------------------------\n",
            "Average score for all folds:\n",
            "> Accuracy: 78.96901567776997\n",
            ">Loss: 1.3281242382785317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01cqJOpIRByn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "2a2c9c43-aef6-471d-e10d-643807c01765"
      },
      "source": [
        "best_model = load_model('modelCNNGeo.h5')\n",
        "Y_pred = best_model.predict(X[test])\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion matrix - Test')\n",
        "y_act = np.argmax(Y[test],axis=1)\n",
        "print(confusion_matrix(y_act,y_pred))\n",
        "print('Classification report')\n",
        "target_names= ['California','Connecticut','Florida','Masachusetts','Michigan','New York','Virginia','Washington']\n",
        "print(classification_report(y_act,y_pred,target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix - Test\n",
            "[[174   0   1  11  19   3  25  19]\n",
            " [  6   0   0   3  18   0   0   9]\n",
            " [  1   0  42   0   2   2   1   2]\n",
            " [ 15   0   0  68   0   8   2  51]\n",
            " [ 33   0   0   5 118   0   0   1]\n",
            " [  9   1   0   5   1  74   7   1]\n",
            " [ 35   0   0   4   2   1  63  12]\n",
            " [ 14   0   0  20   1   2   6 597]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  California       0.61      0.69      0.65       252\n",
            " Connecticut       0.00      0.00      0.00        36\n",
            "     Florida       0.98      0.84      0.90        50\n",
            "Masachusetts       0.59      0.47      0.52       144\n",
            "    Michigan       0.73      0.75      0.74       157\n",
            "    New York       0.82      0.76      0.79        98\n",
            "    Virginia       0.61      0.54      0.57       117\n",
            "  Washington       0.86      0.93      0.90       640\n",
            "\n",
            "    accuracy                           0.76      1494\n",
            "   macro avg       0.65      0.62      0.63      1494\n",
            "weighted avg       0.74      0.76      0.75      1494\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}