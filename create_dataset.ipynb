{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio.SeqIO import parse\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_contents = pd.read_csv(\"sequences.csv\")\n",
    "fasta_file = open(\"sequences.fasta\")\n",
    "records = parse(fasta_file,\"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we find the rows in the **sequences.csv** file, which have the entry in the **accession** column in common with the record id of the records in the fasta file, and we create a new column **Sequence** in the original dataframe filling them with the sequences in the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in records:\n",
    "    cc = 0\n",
    "    for index, row in csv_contents.iterrows():\n",
    "        if row['Accession'] == str(record.id):\n",
    "            csv_contents.at[cc, 'Sequence'] = str(record.seq)\n",
    "            break\n",
    "        cc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can delete those entries which have **NA** in the Sequence column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_contents = csv_contents[csv_contents.Sequence != 'NA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a peek at the different columns and their corresponding *data types* and number of *non-null* entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2051 entries, 0 to 2050\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Accession         2051 non-null   object\n",
      " 1   Release_Date      2051 non-null   object\n",
      " 2   Species           2051 non-null   object\n",
      " 3   Length            2051 non-null   int64 \n",
      " 4   Geo_Location      2047 non-null   object\n",
      " 5   Host              2047 non-null   object\n",
      " 6   Isolation_Source  724 non-null    object\n",
      " 7   Collection_Date   2049 non-null   object\n",
      " 8   Sequence          2051 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 160.2+ KB\n"
     ]
    }
   ],
   "source": [
    "csv_contents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Regular expression `^USA.*` to find all those entries in the `Geo_Location` columns whose values match the given pattern, and remove all the other rows having **Geo_Location** column values not matching the given pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accession</th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>Species</th>\n",
       "      <th>Length</th>\n",
       "      <th>Geo_Location</th>\n",
       "      <th>Host</th>\n",
       "      <th>Isolation_Source</th>\n",
       "      <th>Collection_Date</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MT418880</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29899</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>AAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MT418881</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29899</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>AAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MT418882</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29892</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>ATNCCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MT418883</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29868</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>CCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MT418884</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29893</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>TATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MT418885</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29899</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>AAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MT418886</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29838</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>AACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MT418887</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29860</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>GGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MT418888</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29858</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>TAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MT418889</td>\n",
       "      <td>2020-05-01T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29897</td>\n",
       "      <td>USA: VA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>GGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accession          Release_Date  \\\n",
       "7   MT418880  2020-05-01T00:00:00Z   \n",
       "8   MT418881  2020-05-01T00:00:00Z   \n",
       "9   MT418882  2020-05-01T00:00:00Z   \n",
       "10  MT418883  2020-05-01T00:00:00Z   \n",
       "11  MT418884  2020-05-01T00:00:00Z   \n",
       "12  MT418885  2020-05-01T00:00:00Z   \n",
       "13  MT418886  2020-05-01T00:00:00Z   \n",
       "14  MT418887  2020-05-01T00:00:00Z   \n",
       "15  MT418888  2020-05-01T00:00:00Z   \n",
       "16  MT418889  2020-05-01T00:00:00Z   \n",
       "\n",
       "                                              Species  Length Geo_Location  \\\n",
       "7   Severe acute respiratory syndrome-related coro...   29899      USA: VA   \n",
       "8   Severe acute respiratory syndrome-related coro...   29899      USA: VA   \n",
       "9   Severe acute respiratory syndrome-related coro...   29892      USA: VA   \n",
       "10  Severe acute respiratory syndrome-related coro...   29868      USA: VA   \n",
       "11  Severe acute respiratory syndrome-related coro...   29893      USA: VA   \n",
       "12  Severe acute respiratory syndrome-related coro...   29899      USA: VA   \n",
       "13  Severe acute respiratory syndrome-related coro...   29838      USA: VA   \n",
       "14  Severe acute respiratory syndrome-related coro...   29860      USA: VA   \n",
       "15  Severe acute respiratory syndrome-related coro...   29858      USA: VA   \n",
       "16  Severe acute respiratory syndrome-related coro...   29897      USA: VA   \n",
       "\n",
       "            Host Isolation_Source Collection_Date  \\\n",
       "7   Homo sapiens              NaN         2020-04   \n",
       "8   Homo sapiens              NaN         2020-04   \n",
       "9   Homo sapiens              NaN         2020-04   \n",
       "10  Homo sapiens              NaN         2020-04   \n",
       "11  Homo sapiens              NaN         2020-04   \n",
       "12  Homo sapiens              NaN         2020-04   \n",
       "13  Homo sapiens              NaN         2020-04   \n",
       "14  Homo sapiens              NaN         2020-04   \n",
       "15  Homo sapiens              NaN         2020-04   \n",
       "16  Homo sapiens              NaN         2020-04   \n",
       "\n",
       "                                             Sequence  \n",
       "7   AAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTC...  \n",
       "8   AAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTC...  \n",
       "9   ATNCCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGA...  \n",
       "10  CCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAA...  \n",
       "11  TATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAG...  \n",
       "12  AAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTC...  \n",
       "13  AACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAAT...  \n",
       "14  GGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTT...  \n",
       "15  TAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATC...  \n",
       "16  GGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTT...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern= \"^USA.*\"\n",
    "filter = csv_contents['Geo_Location'].str.contains(pattern,na=False)\n",
    "csv_contents = csv_contents[filter]\n",
    "csv_contents.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally writing the altered dataframe into a **final.csv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_contents.to_csv('final.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check presence of **null** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accession           False\n",
       "Release_Date        False\n",
       "Species             False\n",
       "Length              False\n",
       "Geo_Location        False\n",
       "Host                 True\n",
       "Isolation_Source     True\n",
       "Collection_Date     False\n",
       "Sequence            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo_Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Geo_Location\"].fillna(\"NA\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Unique **Geo_Locations** in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geo_Location'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Datapoints for each **Geo_Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA: WA                      683\n",
      "USA                          223\n",
      "USA: NY                      209\n",
      "USA: CA                      132\n",
      "USA: VA                       93\n",
      "USA: Michigan                 89\n",
      "USA: UT                       54\n",
      "USA: CT                       43\n",
      "USA: ID                       38\n",
      "USA: MA                       19\n",
      "USA: GA                       15\n",
      "USA: IL                        9\n",
      "USA: PA                        9\n",
      "USA: MI                        9\n",
      "USA: FL                        8\n",
      "USA: MN                        8\n",
      "USA: AZ                        7\n",
      "USA: IA                        7\n",
      "USA: San Francisco, CA         7\n",
      "USA: SC                        7\n",
      "USA: NC                        7\n",
      "USA: OR                        5\n",
      "USA: TX                        5\n",
      "USA: NH                        4\n",
      "USA: RI                        4\n",
      "USA: IN                        4\n",
      "USA: NJ                        3\n",
      "USA: OH                        3\n",
      "USA: New Orleans, LA           2\n",
      "USA: MD                        2\n",
      "USA: Illinois                  2\n",
      "USA: NV                        2\n",
      "USA: HI                        2\n",
      "USA: NE                        2\n",
      "USA: CA, San Diego County      1\n",
      "USA: WI                        1\n",
      "USA: North Carolina            1\n",
      "USA: New York                  1\n",
      "USA: DC                        1\n",
      "USA: KS                        1\n",
      "USA: LA                        1\n",
      "USA: MO                        1\n",
      "USA: Snohomish County, WA      1\n",
      "Name: Geo_Location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df['Geo_Location'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release_Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Unique **Release_Dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Release_Date'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Datapoints for each **Release Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-13T00:00:00Z    250\n",
      "2020-04-30T00:00:00Z    222\n",
      "2020-04-23T00:00:00Z    208\n",
      "2020-04-24T00:00:00Z    171\n",
      "2020-04-16T00:00:00Z    111\n",
      "2020-03-31T00:00:00Z    110\n",
      "2020-04-20T00:00:00Z    107\n",
      "2020-04-27T00:00:00Z     91\n",
      "2020-04-06T00:00:00Z     72\n",
      "2020-03-30T00:00:00Z     60\n",
      "2020-04-14T00:00:00Z     52\n",
      "2020-05-01T00:00:00Z     49\n",
      "2020-03-26T00:00:00Z     44\n",
      "2020-04-17T00:00:00Z     40\n",
      "2020-04-11T00:00:00Z     31\n",
      "2020-03-09T00:00:00Z     18\n",
      "2020-04-07T00:00:00Z     16\n",
      "2020-04-08T00:00:00Z     12\n",
      "2020-04-03T00:00:00Z      9\n",
      "2020-03-27T00:00:00Z      9\n",
      "2020-03-12T00:00:00Z      7\n",
      "2020-03-10T00:00:00Z      6\n",
      "2020-04-28T00:00:00Z      4\n",
      "2020-04-15T00:00:00Z      3\n",
      "2020-03-13T00:00:00Z      3\n",
      "2020-02-07T00:00:00Z      3\n",
      "2020-02-24T00:00:00Z      3\n",
      "2020-01-28T00:00:00Z      3\n",
      "2020-02-11T00:00:00Z      2\n",
      "2020-02-05T00:00:00Z      2\n",
      "2020-02-12T00:00:00Z      2\n",
      "2020-01-24T00:00:00Z      1\n",
      "2020-03-16T00:00:00Z      1\n",
      "2020-01-25T00:00:00Z      1\n",
      "2020-03-05T00:00:00Z      1\n",
      "2020-02-27T00:00:00Z      1\n",
      "Name: Release_Date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df['Release_Date'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
